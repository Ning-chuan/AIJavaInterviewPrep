# 第10章：高级并发模式

## 章节概要
本章深入探讨GO语言的高级并发编程模式，包括各种同步原语的使用、并发安全的设计以及并发性能优化技巧。这些模式是大厂面试的重点，也是实际项目中解决复杂并发问题的核心技术。

## 学习目标
- 掌握高级并发编程模式的设计思想和实现原理
- 理解各种同步原语的使用场景和性能特点
- 学会设计并发安全的数据结构和算法
- 了解并发性能优化的方法和最佳实践
- 掌握并发程序的调试和监控技巧
- 理解Go并发模型的底层机制

## 目录结构
- [并发编程的核心挑战](#并发编程的核心挑战)
- [高级并发模式](#101-高级并发模式)
  - [Pipeline模式](#1011-pipeline模式)
  - [Fan-out/Fan-in模式](#1012-fan-outfan-in模式)
  - [Worker Pool模式](#1013-worker-pool模式)
  - [Publish-Subscribe模式](#1014-publish-subscribe模式)
  - [Circuit Breaker模式](#1015-circuit-breaker模式)
  - [Rate Limiter模式](#1016-rate-limiter模式)
  - [Bulkhead模式](#1017-bulkhead模式)
- [同步原语详解](#102-同步原语详解)
- [原子操作](#103-原子操作)
- [并发安全的数据结构](#104-并发安全的数据结构)
- [并发模式的性能优化](#105-并发模式的性能优化)
- [并发调试和监控](#106-并发调试和监控)
- [面试重点总结](#面试重点总结)
- [最佳实践建议](#最佳实践建议)
- [实践练习](#实践练习)

## 前置知识
在学习本章之前，请确保已掌握：
- Go基础语法和goroutine概念
- channel的基本使用
- sync包的基本同步原语
- 内存模型和可见性概念

## 并发编程的核心挑战
在深入具体模式之前，我们需要理解并发编程面临的核心挑战：

### 1. 竞态条件（Race Condition）
```go
// 错误示例：存在竞态条件
var counter int

func increment() {
    counter++ // 非原子操作，存在竞态
}

// 正确示例：使用原子操作
var atomicCounter int64

func safeIncrement() {
    atomic.AddInt64(&atomicCounter, 1)
}
```

### 2. 死锁（Deadlock）
```go
// 死锁示例
func deadlockExample() {
    var mu1, mu2 sync.Mutex
    
    go func() {
        mu1.Lock()
        time.Sleep(100 * time.Millisecond)
        mu2.Lock() // 可能死锁
        mu2.Unlock()
        mu1.Unlock()
    }()
    
    go func() {
        mu2.Lock()
        time.Sleep(100 * time.Millisecond)
        mu1.Lock() // 可能死锁
        mu1.Unlock()
        mu2.Unlock()
    }()
}
```

### 3. 活锁（Livelock）
活锁是指线程不断重试操作但始终无法成功的情况。

### 4. 饥饿（Starvation）
某些goroutine长期无法获得所需资源的情况。

## 主要内容

### 必要的导入包
```go
import (
    "context"
    "fmt"
    "hash/fnv"
    "log"
    "math/rand"
    "net/http"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
    "unsafe"
)
```

### 10.1 高级并发模式

#### 10.1.1 Pipeline模式

**核心思想**：将复杂的数据处理任务分解为多个阶段，每个阶段由独立的goroutine处理，通过channel连接各个阶段，形成数据流水线。

**优势**：
- 提高并发性：各阶段可并行处理
- 降低内存使用：流式处理，无需缓存全部数据
- 提高吞吐量：多阶段同时工作
- 易于扩展：可以轻松添加新的处理阶段

**适用场景**：
- 数据ETL处理
- 图像/视频处理流水线
- 日志处理系统
- 消息处理管道

```go
// Pipeline模式：数据流水线处理
func pipeline() {
    // 第一阶段：生成数据
    numbers := generate(1, 2, 3, 4, 5)
    
    // 第二阶段：平方计算
    squares := square(numbers)
    
    // 第三阶段：过滤偶数
    evens := filter(squares)
    
    // 消费结果
    for result := range evens {
        fmt.Println(result)
    }
}

// 带错误处理的Pipeline
type PipelineData struct {
    Value interface{}
    Error error
}

func pipelineWithError() {
    // 生成数据
    input := generateWithError(1, 2, 3, 4, 5)
    
    // 处理数据
    processed := processWithError(input)
    
    // 消费结果
    for data := range processed {
        if data.Error != nil {
            fmt.Printf("处理错误: %v\n", data.Error)
            continue
        }
        fmt.Printf("处理结果: %v\n", data.Value)
    }
}

func generateWithError(nums ...int) <-chan PipelineData {
    out := make(chan PipelineData)
    go func() {
        defer close(out)
        for _, n := range nums {
            if n < 0 {
                out <- PipelineData{Error: fmt.Errorf("负数不支持: %d", n)}
                continue
            }
            out <- PipelineData{Value: n}
        }
    }()
    return out
}

func processWithError(in <-chan PipelineData) <-chan PipelineData {
    out := make(chan PipelineData)
    go func() {
        defer close(out)
        for data := range in {
            if data.Error != nil {
                out <- data // 传递错误
                continue
            }
            
            // 模拟可能出错的处理
            if num, ok := data.Value.(int); ok && num > 100 {
                out <- PipelineData{Error: fmt.Errorf("数值过大: %d", num)}
                continue
            }
            
            // 正常处理
            if num, ok := data.Value.(int); ok {
                out <- PipelineData{Value: num * num}
            }
        }
    }()
    return out
}

func generate(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            out <- n
        }
    }()
    return out
}

func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            out <- n * n
        }
    }()
    return out
}

func filter(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            if n%2 == 0 {
                out <- n
            }
        }
    }()
    return out
}
```

#### 10.1.2 Fan-out/Fan-in模式

**核心思想**：
- **Fan-out**：将单一数据源的工作分发给多个并行的worker处理
- **Fan-in**：将多个worker的处理结果合并到单一输出流

**优势**：
- 充分利用多核CPU
- 提高处理吞吐量
- 负载均衡
- 容错性好（单个worker失败不影响整体）

**适用场景**：
- CPU密集型任务的并行处理
- 网络请求的并发处理
- 大数据批处理
- 分布式计算

```go
// Fan-out: 将工作分发给多个worker
// Fan-in: 将多个worker的结果合并
func fanOutFanIn() {
    in := generate(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    
    // Fan-out: 启动多个worker
    c1 := square(in)
    c2 := square(in)
    c3 := square(in)
    
    // Fan-in: 合并结果
    for result := range merge(c1, c2, c3) {
        fmt.Println(result)
    }
}

// 动态Fan-out模式：根据CPU核心数动态创建worker
func dynamicFanOut(input <-chan int) <-chan int {
    numWorkers := runtime.NumCPU()
    
    // 创建worker输出channels
    workers := make([]<-chan int, numWorkers)
    for i := 0; i < numWorkers; i++ {
        workers[i] = square(input)
    }
    
    // 合并所有worker的输出
    return merge(workers...)
}

// 带超时的Fan-out模式
func fanOutWithTimeout(input <-chan int, timeout time.Duration) <-chan int {
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()
    
    // 启动多个worker
    workers := make([]<-chan int, 3)
    for i := 0; i < 3; i++ {
        workers[i] = squareWithContext(ctx, input)
    }
    
    return mergeWithContext(ctx, workers...)
}

func squareWithContext(ctx context.Context, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case n, ok := <-in:
                if !ok {
                    return
                }
                select {
                case out <- n * n:
                case <-ctx.Done():
                    return
                }
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

func mergeWithContext(ctx context.Context, cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)
    
    output := func(c <-chan int) {
        defer wg.Done()
        for {
            select {
            case n, ok := <-c:
                if !ok {
                    return
                }
                select {
                case out <- n:
                case <-ctx.Done():
                    return
                }
            case <-ctx.Done():
                return
            }
        }
    }
    
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)
    
    // 为每个输入channel启动一个goroutine
    output := func(c <-chan int) {
        defer wg.Done()
        for n := range c {
            out <- n
        }
    }
    
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }
    
    // 启动goroutine等待所有输入完成后关闭输出channel
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}
```

#### 10.1.3 Worker Pool模式

**核心思想**：维护固定数量的worker goroutine，通过任务队列分发工作，避免无限制创建goroutine导致的资源耗尽。

**优势**：
- 控制并发数量，避免资源耗尽
- 复用goroutine，减少创建销毁开销
- 提供背压机制，防止任务堆积
- 便于监控和管理

**适用场景**：
- HTTP服务器请求处理
- 数据库连接池
- 文件处理任务
- 批量数据处理

**设计要点**：
- 合理设置worker数量（通常为CPU核心数的1-2倍）
- 任务队列大小要适中
- 提供优雅关闭机制
- 支持任务优先级（可选）

```go
// Worker Pool: 固定数量的worker处理任务
type Job struct {
    ID       int
    Data     interface{}
    Result   chan interface{}
    Priority int // 任务优先级
}

type WorkerPool struct {
    workerCount int
    jobQueue    chan Job
    quit        chan bool
}

func NewWorkerPool(workerCount int, queueSize int) *WorkerPool {
    return &WorkerPool{
        workerCount: workerCount,
        jobQueue:    make(chan Job, queueSize),
        quit:        make(chan bool),
    }
}

func (wp *WorkerPool) Start() {
    for i := 0; i < wp.workerCount; i++ {
        go wp.worker(i)
    }
}

func (wp *WorkerPool) worker(id int) {
    for {
        select {
        case job := <-wp.jobQueue:
            fmt.Printf("Worker %d 处理任务 %d\n", id, job.ID)
            
            // 模拟工作
            time.Sleep(time.Millisecond * 100)
            result := fmt.Sprintf("任务 %d 完成", job.ID)
            
            job.Result <- result
            close(job.Result)
            
        case <-wp.quit:
            fmt.Printf("Worker %d 停止\n", id)
            return
        }
    }
}

func (wp *WorkerPool) Submit(job Job) {
    wp.jobQueue <- job
}

func (wp *WorkerPool) Stop() {
    close(wp.quit)
}

// 使用示例
func workerPoolExample() {
    pool := NewWorkerPool(3, 10)
    pool.Start()
    defer pool.Stop()
    
    // 提交任务
    for i := 0; i < 10; i++ {
        job := Job{
            ID:     i,
            Data:   fmt.Sprintf("数据-%d", i),
            Result: make(chan interface{}, 1),
        }
        
        pool.Submit(job)
        
        // 等待结果
        result := <-job.Result
        fmt.Println(result)
    }
}

// 高级Worker Pool实现：支持优先级、监控、优雅关闭
type AdvancedWorkerPool struct {
    workerCount   int
    jobQueue      chan Job
    priorityQueue *PriorityQueue
    quit          chan struct{}
    wg            sync.WaitGroup
    
    // 监控指标
    mu            sync.RWMutex
    totalJobs     int64
    completedJobs int64
    failedJobs    int64
    activeWorkers int32
}

type PriorityQueue struct {
    mu    sync.Mutex
    items []Job
}

func (pq *PriorityQueue) Push(job Job) {
    pq.mu.Lock()
    defer pq.mu.Unlock()
    
    // 按优先级插入（简单实现）
    inserted := false
    for i, item := range pq.items {
        if job.Priority > item.Priority {
            pq.items = append(pq.items[:i], append([]Job{job}, pq.items[i:]...)...)
            inserted = true
            break
        }
    }
    if !inserted {
        pq.items = append(pq.items, job)
    }
}

func (pq *PriorityQueue) Pop() (Job, bool) {
    pq.mu.Lock()
    defer pq.mu.Unlock()
    
    if len(pq.items) == 0 {
        return Job{}, false
    }
    
    job := pq.items[0]
    pq.items = pq.items[1:]
    return job, true
}

func NewAdvancedWorkerPool(workerCount int) *AdvancedWorkerPool {
    return &AdvancedWorkerPool{
        workerCount:   workerCount,
        jobQueue:      make(chan Job, workerCount*2),
        priorityQueue: &PriorityQueue{},
        quit:          make(chan struct{}),
    }
}

func (awp *AdvancedWorkerPool) Start() {
    // 启动任务分发器
    go awp.dispatcher()
    
    // 启动workers
    for i := 0; i < awp.workerCount; i++ {
        awp.wg.Add(1)
        go awp.worker(i)
    }
}

func (awp *AdvancedWorkerPool) dispatcher() {
    ticker := time.NewTicker(10 * time.Millisecond)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            if job, ok := awp.priorityQueue.Pop(); ok {
                select {
                case awp.jobQueue <- job:
                case <-awp.quit:
                    return
                }
            }
        case <-awp.quit:
            return
        }
    }
}

func (awp *AdvancedWorkerPool) worker(id int) {
    defer awp.wg.Done()
    atomic.AddInt32(&awp.activeWorkers, 1)
    defer atomic.AddInt32(&awp.activeWorkers, -1)
    
    for {
        select {
        case job := <-awp.jobQueue:
            awp.processJob(job)
        case <-awp.quit:
            return
        }
    }
}

func (awp *AdvancedWorkerPool) processJob(job Job) {
    defer func() {
        if r := recover(); r != nil {
            atomic.AddInt64(&awp.failedJobs, 1)
            if job.Result != nil {
                job.Result <- fmt.Errorf("任务执行panic: %v", r)
                close(job.Result)
            }
        }
    }()
    
    // 模拟工作
    time.Sleep(time.Millisecond * 100)
    result := fmt.Sprintf("任务 %d 完成", job.ID)
    
    atomic.AddInt64(&awp.completedJobs, 1)
    
    if job.Result != nil {
        job.Result <- result
        close(job.Result)
    }
}

func (awp *AdvancedWorkerPool) Submit(job Job) error {
    atomic.AddInt64(&awp.totalJobs, 1)
    
    select {
    case <-awp.quit:
        return fmt.Errorf("worker pool已关闭")
    default:
        awp.priorityQueue.Push(job)
        return nil
    }
}

func (awp *AdvancedWorkerPool) Stop() {
    close(awp.quit)
    awp.wg.Wait()
}

func (awp *AdvancedWorkerPool) Stats() (total, completed, failed int64, active int32) {
    return atomic.LoadInt64(&awp.totalJobs),
           atomic.LoadInt64(&awp.completedJobs),
           atomic.LoadInt64(&awp.failedJobs),
           atomic.LoadInt32(&awp.activeWorkers)
}
```

#### 10.1.4 Publish-Subscribe模式
```go
// 发布-订阅模式
type PubSub struct {
    mu          sync.RWMutex
    subscribers map[string][]chan interface{}
    closed      bool
}

func NewPubSub() *PubSub {
    return &PubSub{
        subscribers: make(map[string][]chan interface{}),
    }
}

func (ps *PubSub) Subscribe(topic string) <-chan interface{} {
    ps.mu.Lock()
    defer ps.mu.Unlock()
    
    if ps.closed {
        return nil
    }
    
    ch := make(chan interface{}, 1)
    ps.subscribers[topic] = append(ps.subscribers[topic], ch)
    return ch
}

func (ps *PubSub) Publish(topic string, data interface{}) {
    ps.mu.RLock()
    defer ps.mu.RUnlock()
    
    if ps.closed {
        return
    }
    
    for _, ch := range ps.subscribers[topic] {
        select {
        case ch <- data:
        default: // 非阻塞发送
        }
    }
}

func (ps *PubSub) Close() {
    ps.mu.Lock()
    defer ps.mu.Unlock()
    
    if ps.closed {
        return
    }
    
    ps.closed = true
    for _, subscribers := range ps.subscribers {
        for _, ch := range subscribers {
            close(ch)
        }
    }
}

// 使用示例
func pubSubExample() {
    ps := NewPubSub()
    defer ps.Close()
    
    // 订阅者1
    sub1 := ps.Subscribe("news")
    go func() {
        for msg := range sub1 {
            fmt.Printf("订阅者1收到: %v\n", msg)
        }
    }()
    
    // 订阅者2
    sub2 := ps.Subscribe("news")
    go func() {
        for msg := range sub2 {
            fmt.Printf("订阅者2收到: %v\n", msg)
        }
    }()
    
    // 发布消息
    ps.Publish("news", "重要新闻1")
    ps.Publish("news", "重要新闻2")
    
    time.Sleep(time.Second)
}

#### 10.1.5 Circuit Breaker模式

**核心思想**：在分布式系统中，当某个服务出现故障时，快速失败而不是等待超时，避免级联故障。

**状态转换**：
- **Closed**：正常状态，请求正常通过
- **Open**：熔断状态，直接返回错误
- **Half-Open**：半开状态，允许少量请求测试服务是否恢复

```go
// Circuit Breaker实现
type CircuitBreaker struct {
    mu           sync.RWMutex
    state        State
    failureCount int
    lastFailTime time.Time
    
    // 配置参数
    maxFailures  int
    timeout      time.Duration
    resetTimeout time.Duration
}

type State int

const (
    StateClosed State = iota
    StateOpen
    StateHalfOpen
)

func NewCircuitBreaker(maxFailures int, timeout, resetTimeout time.Duration) *CircuitBreaker {
    return &CircuitBreaker{
        state:        StateClosed,
        maxFailures:  maxFailures,
        timeout:      timeout,
        resetTimeout: resetTimeout,
    }
}

func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    // 检查是否需要从Open状态转换到Half-Open
    if cb.state == StateOpen && time.Since(cb.lastFailTime) > cb.resetTimeout {
        cb.state = StateHalfOpen
        cb.failureCount = 0
    }
    
    // 如果是Open状态，直接返回错误
    if cb.state == StateOpen {
        return fmt.Errorf("circuit breaker is open")
    }
    
    // 执行函数
    err := fn()
    
    if err != nil {
        cb.onFailure()
        return err
    }
    
    cb.onSuccess()
    return nil
}

func (cb *CircuitBreaker) onFailure() {
    cb.failureCount++
    cb.lastFailTime = time.Now()
    
    if cb.failureCount >= cb.maxFailures {
        cb.state = StateOpen
    }
}

func (cb *CircuitBreaker) onSuccess() {
    cb.failureCount = 0
    cb.state = StateClosed
}

func (cb *CircuitBreaker) State() State {
    cb.mu.RLock()
    defer cb.mu.RUnlock()
    return cb.state
}

// 使用示例
func circuitBreakerExample() {
    cb := NewCircuitBreaker(3, time.Second*5, time.Second*10)
    
    // 模拟服务调用
    callService := func() error {
        // 模拟50%的失败率
        if rand.Float32() < 0.5 {
            return fmt.Errorf("service error")
        }
        return nil
    }
    
    for i := 0; i < 20; i++ {
        err := cb.Call(callService)
        fmt.Printf("调用 %d: 状态=%v, 错误=%v\n", i+1, cb.State(), err)
        time.Sleep(time.Second)
    }
}

#### 10.1.6 Rate Limiter模式

**核心思想**：控制请求的处理速率，防止系统过载。

**常见算法**：
- **Token Bucket**：令牌桶算法
- **Leaky Bucket**：漏桶算法
- **Fixed Window**：固定窗口
- **Sliding Window**：滑动窗口

```go
// Token Bucket Rate Limiter
type TokenBucket struct {
    mu       sync.Mutex
    tokens   int
    capacity int
    rate     time.Duration
    lastTime time.Time
}

func NewTokenBucket(capacity int, rate time.Duration) *TokenBucket {
    return &TokenBucket{
        tokens:   capacity,
        capacity: capacity,
        rate:     rate,
        lastTime: time.Now(),
    }
}

func (tb *TokenBucket) Allow() bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    now := time.Now()
    elapsed := now.Sub(tb.lastTime)
    
    // 添加新的令牌
    tokensToAdd := int(elapsed / tb.rate)
    if tokensToAdd > 0 {
        tb.tokens = min(tb.capacity, tb.tokens+tokensToAdd)
        tb.lastTime = now
    }
    
    // 检查是否有可用令牌
    if tb.tokens > 0 {
        tb.tokens--
        return true
    }
    
    return false
}

func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}

// Sliding Window Rate Limiter
type SlidingWindowLimiter struct {
    mu       sync.RWMutex
    requests []time.Time
    limit    int
    window   time.Duration
}

func NewSlidingWindowLimiter(limit int, window time.Duration) *SlidingWindowLimiter {
    return &SlidingWindowLimiter{
        requests: make([]time.Time, 0),
        limit:    limit,
        window:   window,
    }
}

func (swl *SlidingWindowLimiter) Allow() bool {
    swl.mu.Lock()
    defer swl.mu.Unlock()
    
    now := time.Now()
    cutoff := now.Add(-swl.window)
    
    // 清理过期的请求记录
    validRequests := 0
    for _, reqTime := range swl.requests {
        if reqTime.After(cutoff) {
            swl.requests[validRequests] = reqTime
            validRequests++
        }
    }
    swl.requests = swl.requests[:validRequests]
    
    // 检查是否超过限制
    if len(swl.requests) >= swl.limit {
        return false
    }
    
    // 记录新请求
    swl.requests = append(swl.requests, now)
    return true
}

// 使用示例
func rateLimiterExample() {
    limiter := NewTokenBucket(10, time.Millisecond*100)
    
    for i := 0; i < 20; i++ {
        if limiter.Allow() {
            fmt.Printf("请求 %d: 允许\n", i+1)
        } else {
            fmt.Printf("请求 %d: 被限流\n", i+1)
        }
        time.Sleep(time.Millisecond * 50)
    }
}

#### 10.1.7 Bulkhead模式

**核心思想**：将系统资源隔离到不同的池中，防止一个组件的故障影响整个系统。

```go
// 资源池隔离
type ResourcePool struct {
    name      string
    resources chan interface{}
    factory   func() interface{}
    cleanup   func(interface{})
}

func NewResourcePool(name string, size int, factory func() interface{}, cleanup func(interface{})) *ResourcePool {
    pool := &ResourcePool{
        name:      name,
        resources: make(chan interface{}, size),
        factory:   factory,
        cleanup:   cleanup,
    }
    
    // 预填充资源池
    for i := 0; i < size; i++ {
        pool.resources <- factory()
    }
    
    return pool
}

func (rp *ResourcePool) Get() interface{} {
    select {
    case resource := <-rp.resources:
        return resource
    default:
        // 如果池为空，创建新资源
        return rp.factory()
    }
}

func (rp *ResourcePool) Put(resource interface{}) {
    select {
    case rp.resources <- resource:
        // 成功放回池中
    default:
        // 池已满，清理资源
        if rp.cleanup != nil {
            rp.cleanup(resource)
        }
    }
}

// 服务隔离示例
type IsolatedService struct {
    dbPool    *ResourcePool
    cachePool *ResourcePool
    httpPool  *ResourcePool
}

func NewIsolatedService() *IsolatedService {
    return &IsolatedService{
        dbPool: NewResourcePool("database", 10, 
            func() interface{} { return &DatabaseConnection{} },
            func(res interface{}) { res.(*DatabaseConnection).Close() }),
        
        cachePool: NewResourcePool("cache", 5,
            func() interface{} { return &CacheConnection{} },
            func(res interface{}) { res.(*CacheConnection).Close() }),
        
        httpPool: NewResourcePool("http", 20,
            func() interface{} { return &http.Client{Timeout: time.Second * 30} },
            nil),
    }
}

type DatabaseConnection struct{}
func (dc *DatabaseConnection) Close() {}

type CacheConnection struct{}
func (cc *CacheConnection) Close() {}

func (is *IsolatedService) ProcessRequest(requestType string) error {
    switch requestType {
    case "database":
        conn := is.dbPool.Get().(*DatabaseConnection)
        defer is.dbPool.Put(conn)
        // 处理数据库请求
        return nil
        
    case "cache":
        conn := is.cachePool.Get().(*CacheConnection)
        defer is.cachePool.Put(conn)
        // 处理缓存请求
        return nil
        
    case "http":
        client := is.httpPool.Get().(*http.Client)
        defer is.httpPool.Put(client)
        // 处理HTTP请求
        return nil
        
    default:
        return fmt.Errorf("unknown request type: %s", requestType)
    }
}
```

### 10.2 同步原语详解

#### 10.2.1 Mutex和RWMutex
```go
// 互斥锁的使用
type Counter struct {
    mu    sync.Mutex
    value int
}

func (c *Counter) Increment() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.value++
}

func (c *Counter) Value() int {
    c.mu.Lock()
    defer c.mu.Unlock()
    return c.value
}

// 读写锁的使用
type Cache struct {
    mu   sync.RWMutex
    data map[string]interface{}
}

func NewCache() *Cache {
    return &Cache{
        data: make(map[string]interface{}),
    }
}

func (c *Cache) Get(key string) (interface{}, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    value, ok := c.data[key]
    return value, ok
}

func (c *Cache) Set(key string, value interface{}) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = value
}

func (c *Cache) Delete(key string) {
    c.mu.Lock()
    defer c.mu.Unlock()
    delete(c.data, key)
}

// 性能对比示例
func mutexVsRWMutex() {
    cache := NewCache()
    
    // 大量读操作
    var wg sync.WaitGroup
    
    // 写操作
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(i int) {
            defer wg.Done()
            cache.Set(fmt.Sprintf("key%d", i), i)
        }(i)
    }
    
    // 读操作
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func(i int) {
            defer wg.Done()
            cache.Get(fmt.Sprintf("key%d", i%10))
        }(i)
    }
    
    wg.Wait()
}
```

#### 10.2.2 WaitGroup
```go
// WaitGroup的高级用法
func waitGroupAdvanced() {
    var wg sync.WaitGroup
    
    // 动态添加任务
    tasks := []func(){
        func() { fmt.Println("任务1"); time.Sleep(time.Second) },
        func() { fmt.Println("任务2"); time.Sleep(time.Second * 2) },
        func() { fmt.Println("任务3"); time.Sleep(time.Second * 3) },
    }
    
    for i, task := range tasks {
        wg.Add(1)
        go func(id int, fn func()) {
            defer wg.Done()
            fmt.Printf("开始执行任务 %d\n", id)
            fn()
            fmt.Printf("任务 %d 完成\n", id)
        }(i+1, task)
    }
    
    // 等待所有任务完成
    wg.Wait()
    fmt.Println("所有任务完成")
}

// 带超时的WaitGroup
func waitGroupWithTimeout(timeout time.Duration) error {
    var wg sync.WaitGroup
    done := make(chan struct{})
    
    // 启动任务
    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            // 模拟长时间运行的任务
            time.Sleep(time.Second * time.Duration(id))
            fmt.Printf("任务 %d 完成\n", id)
        }(i)
    }
    
    // 等待完成信号
    go func() {
        wg.Wait()
        close(done)
    }()
    
    // 等待完成或超时
    select {
    case <-done:
        fmt.Println("所有任务在超时前完成")
        return nil
    case <-time.After(timeout):
        fmt.Println("任务执行超时")
        return fmt.Errorf("任务执行超时")
    }
}
```

#### 10.2.3 Once
```go
// Once的使用场景
type Singleton struct {
    data string
}

var (
    instance *Singleton
    once     sync.Once
)

func GetSingleton() *Singleton {
    once.Do(func() {
        fmt.Println("创建单例实例")
        instance = &Singleton{data: "singleton"}
    })
    return instance
}

// 资源初始化
type Database struct {
    conn *sql.DB
}

var (
    db     *Database
    dbOnce sync.Once
)

func GetDatabase() *Database {
    dbOnce.Do(func() {
        fmt.Println("初始化数据库连接")
        conn, err := sql.Open("mysql", "dsn")
        if err != nil {
            panic(err)
        }
        db = &Database{conn: conn}
    })
    return db
}

// 配置加载
type Config struct {
    settings map[string]string
}

var (
    config     *Config
    configOnce sync.Once
)

func GetConfig() *Config {
    configOnce.Do(func() {
        fmt.Println("加载配置文件")
        config = &Config{
            settings: map[string]string{
                "host": "localhost",
                "port": "8080",
            },
        }
    })
    return config
}
```

#### 10.2.4 Cond
```go
// Cond的使用：生产者-消费者模式
type Queue struct {
    mu    sync.Mutex
    cond  *sync.Cond
    items []interface{}
    max   int
}

func NewQueue(max int) *Queue {
    q := &Queue{
        items: make([]interface{}, 0),
        max:   max,
    }
    q.cond = sync.NewCond(&q.mu)
    return q
}

func (q *Queue) Put(item interface{}) {
    q.mu.Lock()
    defer q.mu.Unlock()
    
    // 等待队列有空间
    for len(q.items) >= q.max {
        q.cond.Wait()
    }
    
    q.items = append(q.items, item)
    fmt.Printf("生产: %v, 队列长度: %d\n", item, len(q.items))
    
    // 通知等待的消费者
    q.cond.Signal()
}

func (q *Queue) Get() interface{} {
    q.mu.Lock()
    defer q.mu.Unlock()
    
    // 等待队列有数据
    for len(q.items) == 0 {
        q.cond.Wait()
    }
    
    item := q.items[0]
    q.items = q.items[1:]
    fmt.Printf("消费: %v, 队列长度: %d\n", item, len(q.items))
    
    // 通知等待的生产者
    q.cond.Signal()
    
    return item
}

// 使用示例
func condExample() {
    queue := NewQueue(3)
    
    // 生产者
    go func() {
        for i := 0; i < 10; i++ {
            queue.Put(fmt.Sprintf("item-%d", i))
            time.Sleep(time.Millisecond * 100)
        }
    }()
    
    // 消费者
    go func() {
        for i := 0; i < 10; i++ {
            item := queue.Get()
            fmt.Printf("处理: %v\n", item)
            time.Sleep(time.Millisecond * 200)
        }
    }()
    
    time.Sleep(time.Second * 5)
}
```

### 10.3 原子操作

#### 10.3.1 atomic包的使用
```go
import "sync/atomic"

// 原子计数器
type AtomicCounter struct {
    value int64
}

func (c *AtomicCounter) Increment() {
    atomic.AddInt64(&c.value, 1)
}

func (c *AtomicCounter) Decrement() {
    atomic.AddInt64(&c.value, -1)
}

func (c *AtomicCounter) Value() int64 {
    return atomic.LoadInt64(&c.value)
}

func (c *AtomicCounter) Reset() {
    atomic.StoreInt64(&c.value, 0)
}

func (c *AtomicCounter) CompareAndSwap(old, new int64) bool {
    return atomic.CompareAndSwapInt64(&c.value, old, new)
}

// 原子指针操作
type Node struct {
    data interface{}
    next *Node
}

type LockFreeStack struct {
    head unsafe.Pointer
}

func (s *LockFreeStack) Push(data interface{}) {
    newNode := &Node{data: data}
    
    for {
        head := (*Node)(atomic.LoadPointer(&s.head))
        newNode.next = head
        
        if atomic.CompareAndSwapPointer(&s.head, 
            unsafe.Pointer(head), unsafe.Pointer(newNode)) {
            break
        }
    }
}

func (s *LockFreeStack) Pop() interface{} {
    for {
        head := (*Node)(atomic.LoadPointer(&s.head))
        if head == nil {
            return nil
        }
        
        if atomic.CompareAndSwapPointer(&s.head,
            unsafe.Pointer(head), unsafe.Pointer(head.next)) {
            return head.data
        }
    }
}

// 性能对比：原子操作 vs 互斥锁
func atomicVsMutex() {
    const iterations = 1000000
    
    // 使用原子操作
    var atomicCounter int64
    start := time.Now()
    
    var wg sync.WaitGroup
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < iterations/10; j++ {
                atomic.AddInt64(&atomicCounter, 1)
            }
        }()
    }
    wg.Wait()
    
    atomicTime := time.Since(start)
    fmt.Printf("原子操作耗时: %v, 结果: %d\n", atomicTime, atomicCounter)
    
    // 使用互斥锁
    var mutexCounter int64
    var mu sync.Mutex
    start = time.Now()
    
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < iterations/10; j++ {
                mu.Lock()
                mutexCounter++
                mu.Unlock()
            }
        }()
    }
    wg.Wait()
    
    mutexTime := time.Since(start)
    fmt.Printf("互斥锁耗时: %v, 结果: %d\n", mutexTime, mutexCounter)
}
```

### 10.4 并发安全的数据结构

#### 10.4.1 并发安全的Map
```go
// 使用sync.Map
func syncMapExample() {
    var m sync.Map
    
    // 存储
    m.Store("key1", "value1")
    m.Store("key2", "value2")
    
    // 读取
    if value, ok := m.Load("key1"); ok {
        fmt.Printf("key1: %v\n", value)
    }
    
    // 读取或存储
    actual, loaded := m.LoadOrStore("key3", "value3")
    fmt.Printf("key3: %v, 已存在: %v\n", actual, loaded)
    
    // 删除
    m.Delete("key2")
    
    // 遍历
    m.Range(func(key, value interface{}) bool {
        fmt.Printf("%v: %v\n", key, value)
        return true // 继续遍历
    })
}

// 自定义并发安全Map
type SafeMap struct {
    mu   sync.RWMutex
    data map[string]interface{}
}

func NewSafeMap() *SafeMap {
    return &SafeMap{
        data: make(map[string]interface{}),
    }
}

func (sm *SafeMap) Set(key string, value interface{}) {
    sm.mu.Lock()
    defer sm.mu.Unlock()
    sm.data[key] = value
}

func (sm *SafeMap) Get(key string) (interface{}, bool) {
    sm.mu.RLock()
    defer sm.mu.RUnlock()
    value, ok := sm.data[key]
    return value, ok
}

func (sm *SafeMap) Delete(key string) {
    sm.mu.Lock()
    defer sm.mu.Unlock()
    delete(sm.data, key)
}

func (sm *SafeMap) Len() int {
    sm.mu.RLock()
    defer sm.mu.RUnlock()
    return len(sm.data)
}

func (sm *SafeMap) Keys() []string {
    sm.mu.RLock()
    defer sm.mu.RUnlock()
    
    keys := make([]string, 0, len(sm.data))
    for k := range sm.data {
        keys = append(keys, k)
    }
    return keys
}
```

#### 10.4.2 并发安全的切片
```go
// 并发安全的切片
type SafeSlice struct {
    mu   sync.RWMutex
    data []interface{}
}

func NewSafeSlice() *SafeSlice {
    return &SafeSlice{
        data: make([]interface{}, 0),
    }
}

func (ss *SafeSlice) Append(item interface{}) {
    ss.mu.Lock()
    defer ss.mu.Unlock()
    ss.data = append(ss.data, item)
}

func (ss *SafeSlice) Get(index int) (interface{}, bool) {
    ss.mu.RLock()
    defer ss.mu.RUnlock()
    
    if index < 0 || index >= len(ss.data) {
        return nil, false
    }
    return ss.data[index], true
}

func (ss *SafeSlice) Set(index int, item interface{}) bool {
    ss.mu.Lock()
    defer ss.mu.Unlock()
    
    if index < 0 || index >= len(ss.data) {
        return false
    }
    ss.data[index] = item
    return true
}

func (ss *SafeSlice) Len() int {
    ss.mu.RLock()
    defer ss.mu.RUnlock()
    return len(ss.data)
}

func (ss *SafeSlice) ToSlice() []interface{} {
    ss.mu.RLock()
    defer ss.mu.RUnlock()
    
    result := make([]interface{}, len(ss.data))
    copy(result, ss.data)
    return result
}
```

### 10.5 并发模式的性能优化

#### 10.5.1 减少锁竞争
```go
// 分段锁减少竞争
type ShardedMap struct {
    shards []*SafeMap
    mask   uint32
}

func NewShardedMap(shardCount int) *ShardedMap {
    // 确保shardCount是2的幂
    if shardCount&(shardCount-1) != 0 {
        panic("shardCount must be power of 2")
    }
    
    shards := make([]*SafeMap, shardCount)
    for i := range shards {
        shards[i] = NewSafeMap()
    }
    
    return &ShardedMap{
        shards: shards,
        mask:   uint32(shardCount - 1),
    }
}

func (sm *ShardedMap) getShard(key string) *SafeMap {
    hash := fnv.New32a()
    hash.Write([]byte(key))
    return sm.shards[hash.Sum32()&sm.mask]
}

func (sm *ShardedMap) Set(key string, value interface{}) {
    shard := sm.getShard(key)
    shard.Set(key, value)
}

func (sm *ShardedMap) Get(key string) (interface{}, bool) {
    shard := sm.getShard(key)
    return shard.Get(key)
}

func (sm *ShardedMap) Delete(key string) {
    shard := sm.getShard(key)
    shard.Delete(key)
}
```

#### 10.5.2 无锁编程
```go
// 无锁队列实现
type LockFreeQueue struct {
    head unsafe.Pointer
    tail unsafe.Pointer
}

type queueNode struct {
    data interface{}
    next unsafe.Pointer
}

func NewLockFreeQueue() *LockFreeQueue {
    node := &queueNode{}
    q := &LockFreeQueue{
        head: unsafe.Pointer(node),
        tail: unsafe.Pointer(node),
    }
    return q
}

func (q *LockFreeQueue) Enqueue(data interface{}) {
    newNode := &queueNode{data: data}
    
    for {
        tail := (*queueNode)(atomic.LoadPointer(&q.tail))
        next := (*queueNode)(atomic.LoadPointer(&tail.next))
        
        if tail == (*queueNode)(atomic.LoadPointer(&q.tail)) {
            if next == nil {
                if atomic.CompareAndSwapPointer(&tail.next,
                    unsafe.Pointer(next), unsafe.Pointer(newNode)) {
                    break
                }
            } else {
                atomic.CompareAndSwapPointer(&q.tail,
                    unsafe.Pointer(tail), unsafe.Pointer(next))
            }
        }
    }
    
    atomic.CompareAndSwapPointer(&q.tail,
        unsafe.Pointer((*queueNode)(atomic.LoadPointer(&q.tail))),
        unsafe.Pointer(newNode))
}

func (q *LockFreeQueue) Dequeue() interface{} {
    for {
        head := (*queueNode)(atomic.LoadPointer(&q.head))
        tail := (*queueNode)(atomic.LoadPointer(&q.tail))
        next := (*queueNode)(atomic.LoadPointer(&head.next))
        
        if head == (*queueNode)(atomic.LoadPointer(&q.head)) {
            if head == tail {
                if next == nil {
                    return nil // 队列为空
                }
                atomic.CompareAndSwapPointer(&q.tail,
                    unsafe.Pointer(tail), unsafe.Pointer(next))
            } else {
                data := next.data
                if atomic.CompareAndSwapPointer(&q.head,
                    unsafe.Pointer(head), unsafe.Pointer(next)) {
                    return data
                }
            }
        }
    }
}
```

#### 10.5.3 批处理优化
```go
// 批处理写入优化
type BatchWriter struct {
    mu       sync.Mutex
    buffer   []interface{}
    batchSize int
    flushInterval time.Duration
    writer   func([]interface{}) error
    timer    *time.Timer
}

func NewBatchWriter(batchSize int, flushInterval time.Duration,
    writer func([]interface{}) error) *BatchWriter {
    
    bw := &BatchWriter{
        buffer:        make([]interface{}, 0, batchSize),
        batchSize:     batchSize,
        flushInterval: flushInterval,
        writer:        writer,
    }
    
    bw.timer = time.AfterFunc(flushInterval, bw.flush)
    return bw
}

func (bw *BatchWriter) Write(data interface{}) error {
    bw.mu.Lock()
    defer bw.mu.Unlock()
    
    bw.buffer = append(bw.buffer, data)
    
    if len(bw.buffer) >= bw.batchSize {
        return bw.flushLocked()
    }
    
    return nil
}

func (bw *BatchWriter) flush() {
    bw.mu.Lock()
    defer bw.mu.Unlock()
    bw.flushLocked()
}

func (bw *BatchWriter) flushLocked() error {
    if len(bw.buffer) == 0 {
        return nil
    }
    
    // 重置定时器
    bw.timer.Reset(bw.flushInterval)
    
    // 写入数据
    err := bw.writer(bw.buffer)
    
    // 清空缓冲区
    bw.buffer = bw.buffer[:0]
    
    return err
}

func (bw *BatchWriter) Close() error {
    bw.timer.Stop()
    return bw.flushLocked()
}
```

### 10.6 并发调试和监控

#### 10.6.1 竞态检测
```go
// 使用 go run -race 检测竞态条件
func raceConditionExample() {
    var counter int
    var wg sync.WaitGroup
    
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < 1000; j++ {
                counter++ // 竞态条件
            }
        }()
    }
    
    wg.Wait()
    fmt.Printf("Counter: %d\n", counter)
}

// 修复竞态条件
func fixedRaceCondition() {
    var counter int64
    var wg sync.WaitGroup
    
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < 1000; j++ {
                atomic.AddInt64(&counter, 1)
            }
        }()
    }
    
    wg.Wait()
    fmt.Printf("Counter: %d\n", counter)
}
```

#### 10.6.2 死锁检测
```go
// 死锁示例
func deadlockExample() {
    var mu1, mu2 sync.Mutex
    
    go func() {
        mu1.Lock()
        fmt.Println("Goroutine 1: 获得锁1")
        time.Sleep(time.Second)
        
        mu2.Lock() // 等待锁2
        fmt.Println("Goroutine 1: 获得锁2")
        mu2.Unlock()
        mu1.Unlock()
    }()
    
    go func() {
        mu2.Lock()
        fmt.Println("Goroutine 2: 获得锁2")
        time.Sleep(time.Second)
        
        mu1.Lock() // 等待锁1，形成死锁
        fmt.Println("Goroutine 2: 获得锁1")
        mu1.Unlock()
        mu2.Unlock()
    }()
    
    time.Sleep(time.Second * 5)
}

// 避免死锁：统一锁顺序
func avoidDeadlock() {
    var mu1, mu2 sync.Mutex
    
    lockInOrder := func(first, second *sync.Mutex) {
        first.Lock()
        second.Lock()
    }
    
    unlockInOrder := func(first, second *sync.Mutex) {
        second.Unlock()
        first.Unlock()
    }
    
    go func() {
        lockInOrder(&mu1, &mu2)
        fmt.Println("Goroutine 1: 获得所有锁")
        time.Sleep(time.Second)
        unlockInOrder(&mu1, &mu2)
    }()
    
    go func() {
        lockInOrder(&mu1, &mu2) // 相同的锁顺序
        fmt.Println("Goroutine 2: 获得所有锁")
        time.Sleep(time.Second)
        unlockInOrder(&mu1, &mu2)
    }()
    
    time.Sleep(time.Second * 3)
}
```

## 面试重点总结

### 核心概念理解
1. **并发 vs 并行**
   - 并发：逻辑上同时处理多个任务
   - 并行：物理上同时执行多个任务
   - Go的并发模型基于CSP（Communicating Sequential Processes）

2. **Goroutine调度机制**
   - GMP模型：G(Goroutine)、M(Machine/OS Thread)、P(Processor)
   - 工作窃取算法
   - 抢占式调度

3. **内存模型和可见性**
   - happens-before关系
   - 内存屏障
   - 缓存一致性

### 常见面试问题

#### 1. 如何选择合适的并发模式？
```go
// 决策树
func chooseConcurrencyPattern(scenario string) string {
    switch scenario {
    case "数据流处理":
        return "Pipeline模式"
    case "CPU密集型任务":
        return "Fan-out/Fan-in模式"
    case "限制并发数量":
        return "Worker Pool模式"
    case "事件通知":
        return "Publish-Subscribe模式"
    case "服务容错":
        return "Circuit Breaker模式"
    case "流量控制":
        return "Rate Limiter模式"
    case "资源隔离":
        return "Bulkhead模式"
    default:
        return "根据具体需求分析"
    }
}
```

#### 2. 如何避免goroutine泄漏？
```go
// 错误示例：goroutine泄漏
func badExample() {
    ch := make(chan int)
    go func() {
        ch <- 1 // 如果没有接收者，goroutine会永远阻塞
    }()
    // 函数返回，但goroutine仍在运行
}

// 正确示例：使用context控制生命周期
func goodExample(ctx context.Context) {
    ch := make(chan int, 1) // 使用缓冲channel
    go func() {
        select {
        case ch <- 1:
        case <-ctx.Done():
            return
        }
    }()
}
```

#### 3. 如何处理panic在goroutine中的传播？
```go
func safeConcurrentExecution() {
    var wg sync.WaitGroup
    
    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func(id int) {
            defer func() {
                if r := recover(); r != nil {
                    fmt.Printf("Goroutine %d panic: %v\n", id, r)
                }
                wg.Done()
            }()
            
            // 可能panic的代码
            if id == 3 {
                panic("something went wrong")
            }
            fmt.Printf("Goroutine %d completed\n", id)
        }(i)
    }
    
    wg.Wait()
}
```

#### 4. 如何实现优雅关闭？
```go
type Server struct {
    quit chan struct{}
    wg   sync.WaitGroup
}

func (s *Server) Start() {
    s.quit = make(chan struct{})
    
    // 启动多个worker
    for i := 0; i < 3; i++ {
        s.wg.Add(1)
        go s.worker(i)
    }
}

func (s *Server) worker(id int) {
    defer s.wg.Done()
    
    ticker := time.NewTicker(time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            fmt.Printf("Worker %d working\n", id)
        case <-s.quit:
            fmt.Printf("Worker %d shutting down\n", id)
            return
        }
    }
}

func (s *Server) Stop() {
    close(s.quit)
    s.wg.Wait()
    fmt.Println("Server stopped gracefully")
}
```

### 性能优化要点

#### 1. 减少锁竞争
```go
// 使用分段锁
type ShardedCounter struct {
    shards []struct {
        mu    sync.Mutex
        count int64
    }
}

func NewShardedCounter(shardCount int) *ShardedCounter {
    return &ShardedCounter{
        shards: make([]struct {
            mu    sync.Mutex
            count int64
        }, shardCount),
    }
}

func (sc *ShardedCounter) Increment(key string) {
    shard := &sc.shards[hash(key)%len(sc.shards)]
    shard.mu.Lock()
    shard.count++
    shard.mu.Unlock()
}

// 简单的hash函数实现
func hash(s string) int {
    h := fnv.New32a()
    h.Write([]byte(s))
    return int(h.Sum32())
}
```

#### 2. 使用对象池减少GC压力
```go
var bufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 1024)
    },
}

func processData(data []byte) {
    buf := bufferPool.Get().([]byte)
    defer bufferPool.Put(buf)
    
    // 使用buf处理数据
}
```

#### 3. 批处理优化
```go
type BatchProcessor struct {
    items     []interface{}
    batchSize int
    processor func([]interface{})
    mu        sync.Mutex
}

func (bp *BatchProcessor) Add(item interface{}) {
    bp.mu.Lock()
    defer bp.mu.Unlock()
    
    bp.items = append(bp.items, item)
    if len(bp.items) >= bp.batchSize {
        bp.flush()
    }
}

func (bp *BatchProcessor) flush() {
    if len(bp.items) > 0 {
        bp.processor(bp.items)
        bp.items = bp.items[:0]
    }
}
```

### 调试和监控

#### 1. 使用pprof分析并发性能
```go
import _ "net/http/pprof"

func main() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    // 你的应用代码
}

// 访问 http://localhost:6060/debug/pprof/goroutine 查看goroutine信息
```

#### 2. 竞态检测
```bash
# 编译时启用竞态检测
go build -race

# 运行时检测
go run -race main.go

# 测试时检测
go test -race
```

#### 3. 死锁检测工具
```go
// 使用go-deadlock库替换sync包进行死锁检测
import "github.com/sasha-s/go-deadlock"

var mu deadlock.Mutex // 替换 sync.Mutex
```

## 最佳实践建议

### 1. 设计原则
- **优先使用channel进行通信**，而不是共享内存
- **保持goroutine的生命周期简单明确**
- **避免过度并发**，合理控制goroutine数量
- **使用context进行取消和超时控制**

### 2. 错误处理
- **每个goroutine都应该有错误处理机制**
- **使用errgroup简化错误收集**
- **panic应该在goroutine内部处理**

### 3. 资源管理
- **及时关闭channel和释放资源**
- **使用defer确保资源清理**
- **避免goroutine泄漏**

### 4. 测试策略
- **编写并发安全的测试**
- **使用压力测试验证性能**
- **模拟各种并发场景**

## 实践练习

### 初级练习
1. **实现一个并发安全的计数器**
   - 支持增加、减少、获取值操作
   - 比较mutex、atomic、channel三种实现方式的性能

2. **实现简单的生产者-消费者模式**
   - 多个生产者，多个消费者
   - 支持优雅关闭

### 中级练习
3. **实现一个并发缓存系统**
   - 支持TTL过期
   - LRU淘汰策略
   - 并发安全

4. **实现一个任务调度器**
   - 支持任务优先级
   - 支持延时执行
   - 支持任务取消

### 高级练习
5. **实现一个分布式限流器**
   - 支持多种限流算法
   - 支持集群同步
   - 支持动态配置

6. **实现一个高性能的消息队列**
   - 支持持久化
   - 支持消息确认
   - 支持集群部署

## 扩展阅读
- Go并发编程实战
- Effective Go并发部分
- Go内存模型官方文档
- 《Go语言高级编程》并发章节
- 《Go语言实战》并发模式章节 