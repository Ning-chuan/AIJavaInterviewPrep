# 第13章：文件操作与IO

## 章节概要
本章深入讲解GO语言中的文件操作和输入输出处理，包括文件读写、目录操作、IO接口设计以及高性能IO处理技巧。文件I/O是几乎所有应用程序不可或缺的部分，Go提供了强大而灵活的文件操作API，掌握这些知识对于开发高性能可靠的服务端应用至关重要。

## 学习目标
- 掌握GO语言的文件操作API
- 理解IO接口的设计和使用
- 学会处理各种文件格式
- 了解高性能IO编程技巧
- 掌握文件资源管理的最佳实践

## 主要内容

### 13.1 文件基础操作

#### 13.1.1 文件的创建、打开和关闭

在Go语言中，文件操作主要通过`os`包实现。以下是基本文件操作的核心函数：

```go
// 创建文件
file, err := os.Create("filename.txt")
if err != nil {
    log.Fatal(err)
}

// 打开文件（只读模式）
file, err := os.Open("filename.txt")
if err != nil {
    log.Fatal(err)
}

// 打开文件（可读写模式）
file, err := os.OpenFile("filename.txt", os.O_RDWR|os.O_CREATE, 0666)
if err != nil {
    log.Fatal(err)
}

// 关闭文件（务必在操作完成后关闭）
defer file.Close()
```

文件操作的权限标志：
- `O_RDONLY`：只读模式
- `O_WRONLY`：只写模式
- `O_RDWR`：读写模式
- `O_APPEND`：追加模式
- `O_CREATE`：如果不存在则创建
- `O_EXCL`：与O_CREATE一起使用，文件必须不存在
- `O_TRUNC`：打开时清空文件

#### 13.1.2 文件信息获取和权限管理

文件元数据是文件本身的属性信息，Go提供了便捷的方式获取和修改这些信息：

```go
// 获取文件信息
fileInfo, err := os.Stat("filename.txt")
if err != nil {
    log.Fatal(err)
}

// 检查文件是否存在
if _, err := os.Stat("filename.txt"); os.IsNotExist(err) {
    fmt.Println("文件不存在")
}

// 文件信息的常用方法
fmt.Println("文件名:", fileInfo.Name())
fmt.Println("大小:", fileInfo.Size(), "字节")
fmt.Println("权限:", fileInfo.Mode())
fmt.Println("修改时间:", fileInfo.ModTime())
fmt.Println("是否是目录:", fileInfo.IsDir())

// 修改文件权限
err = os.Chmod("filename.txt", 0644)
if err != nil {
    log.Fatal(err)
}

// 修改文件所有者
err = os.Chown("filename.txt", uid, gid)
if err != nil {
    log.Fatal(err)
}
```

#### 13.1.3 文件路径处理和跨平台兼容性

Go的`path/filepath`包提供了处理文件路径的跨平台解决方案：

```go
// 连接路径元素
fullPath := filepath.Join("dir", "subdir", "file.txt")

// 获取绝对路径
absPath, err := filepath.Abs("relative/path")
if err != nil {
    log.Fatal(err)
}

// 分割路径获取目录和文件名
dir, file := filepath.Split("/home/user/file.txt")

// 获取文件扩展名
ext := filepath.Ext("file.txt") // 返回 ".txt"

// 规范化路径（处理../和./）
cleanPath := filepath.Clean("dir/../otherdir/./file.txt")

// 匹配文件模式
matches, err := filepath.Glob("*.txt")
if err != nil {
    log.Fatal(err)
}
```

#### 13.1.4 临时文件和目录操作

临时文件常用于数据处理的中间阶段：

```go
// 创建临时文件
tempFile, err := os.CreateTemp("", "prefix-*.txt")
if err != nil {
    log.Fatal(err)
}
defer os.Remove(tempFile.Name()) // 使用完毕后删除
defer tempFile.Close()

// 创建临时目录
tempDir, err := os.MkdirTemp("", "prefix-*")
if err != nil {
    log.Fatal(err)
}
defer os.RemoveAll(tempDir) // 递归删除目录及其内容
```

### 13.2 文件读写操作

#### 13.2.1 基本读写方法

Go提供了多种文件读写方式，从基本的字节操作到高级的格式化读写：

```go
// 写入字节
data := []byte("Hello, Go!")
err = os.WriteFile("file.txt", data, 0644)
if err != nil {
    log.Fatal(err)
}

// 读取整个文件
content, err := os.ReadFile("file.txt")
if err != nil {
    log.Fatal(err)
}
fmt.Println(string(content))

// 使用Write方法写入
file, err := os.Create("file.txt")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

bytesWritten, err := file.Write([]byte("直接写入字节"))
if err != nil {
    log.Fatal(err)
}
fmt.Printf("写入了%d个字节\n", bytesWritten)

// 使用WriteString方法写入字符串
bytesWritten, err = file.WriteString("直接写入字符串")
if err != nil {
    log.Fatal(err)
}

// 使用Read方法读取
file, err = os.Open("file.txt")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

buffer := make([]byte, 1024)
bytesRead, err := file.Read(buffer)
if err != nil && err != io.EOF {
    log.Fatal(err)
}
fmt.Printf("读取了%d个字节: %s\n", bytesRead, buffer[:bytesRead])
```

#### 13.2.2 缓冲读写

对于频繁的读写操作，使用缓冲可以显著提高性能：

```go
// 缓冲写入
file, err := os.Create("file.txt")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

writer := bufio.NewWriter(file)
_, err = writer.WriteString("使用缓冲写入的文本\n")
if err != nil {
    log.Fatal(err)
}
// 确保数据从缓冲区刷新到文件
err = writer.Flush()
if err != nil {
    log.Fatal(err)
}

// 缓冲读取
file, err = os.Open("file.txt")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

reader := bufio.NewReader(file)
// 按行读取
line, err := reader.ReadString('\n')
if err != nil && err != io.EOF {
    log.Fatal(err)
}
fmt.Print("读取的行: ", line)

// 使用Scanner逐行读取（更简洁）
file, err = os.Open("file.txt")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

scanner := bufio.NewScanner(file)
for scanner.Scan() {
    fmt.Println(scanner.Text())
}
if err := scanner.Err(); err != nil {
    log.Fatal(err)
}
```

#### 13.2.3 随机访问和定位

随机访问允许读写文件的特定位置：

```go
// 使用Seek定位到文件特定位置
file, err := os.OpenFile("file.txt", os.O_RDWR, 0644)
if err != nil {
    log.Fatal(err)
}
defer file.Close()

// 从文件开始位置偏移10字节
newPosition, err := file.Seek(10, 0)
if err != nil {
    log.Fatal(err)
}
fmt.Printf("当前位置: %d\n", newPosition)

// Seek的第二个参数常量:
// io.SeekStart (0): 从文件开始处偏移
// io.SeekCurrent (1): 从当前位置偏移
// io.SeekEnd (2): 从文件末尾偏移

// 从当前位置向后偏移5字节
newPosition, err = file.Seek(5, io.SeekCurrent)
if err != nil {
    log.Fatal(err)
}

// 定位到文件末尾
newPosition, err = file.Seek(0, io.SeekEnd)
if err != nil {
    log.Fatal(err)
}

// 在特定位置写入数据
_, err = file.WriteAt([]byte("在特定位置写入"), 20)
if err != nil {
    log.Fatal(err)
}

// 从特定位置读取数据
buffer := make([]byte, 10)
_, err = file.ReadAt(buffer, 20)
if err != nil && err != io.EOF {
    log.Fatal(err)
}
```

#### 13.2.4 大文件处理策略

处理大文件时需要特别注意内存使用：

```go
// 分块读取大文件
file, err := os.Open("largefile.dat")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

buffer := make([]byte, 4096) // 4KB的缓冲区
for {
    bytesRead, err := file.Read(buffer)
    if err != nil {
        if err == io.EOF {
            break // 文件结束
        }
        log.Fatal(err)
    }
    
    // 处理读取的数据块
    processData(buffer[:bytesRead])
}

// 使用io.Copy进行大文件复制
source, err := os.Open("source.file")
if err != nil {
    log.Fatal(err)
}
defer source.Close()

destination, err := os.Create("destination.file")
if err != nil {
    log.Fatal(err)
}
defer destination.Close()

bytesWritten, err := io.Copy(destination, source)
if err != nil {
    log.Fatal(err)
}
fmt.Printf("复制了%d字节\n", bytesWritten)
```

面试中的性能优化考点：
- 大文件处理时应避免一次性将整个文件读入内存
- 合理选择缓冲区大小：太小会导致过多的系统调用，太大会占用过多内存
- 对于已知大小的数据块，预分配切片可以避免动态扩容的开销
- 使用`io.Copy`代替手动循环读写可以获得更好的性能

### 13.3 IO接口体系

Go语言的IO操作建立在一系列精心设计的接口之上，这种设计使得IO操作具有极高的灵活性和可组合性。

#### 13.3.1 io.Reader和io.Writer接口

这两个接口是Go IO体系的基石：

```go
// io.Reader接口定义
type Reader interface {
    Read(p []byte) (n int, err error)
}

// io.Writer接口定义
type Writer interface {
    Write(p []byte) (n int, err error)
}
```

使用示例：

```go
// 从标准输入读取数据到标准输出
func Copy() error {
    // os.Stdin实现了io.Reader接口
    // os.Stdout实现了io.Writer接口
    _, err := io.Copy(os.Stdout, os.Stdin)
    return err
}

// 字符串作为Reader
reader := strings.NewReader("Hello, Reader!")
buffer := make([]byte, 8)
for {
    n, err := reader.Read(buffer)
    if err == io.EOF {
        break
    }
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("读取了%d字节: %s\n", n, buffer[:n])
}

// 使用bytes.Buffer作为Writer
var buf bytes.Buffer
buf.Write([]byte("Hello, "))
buf.WriteString("Writer!")
fmt.Println(buf.String()) // 输出: Hello, Writer!
```

#### 13.3.2 io.Closer和io.Seeker接口

```go
// io.Closer接口
type Closer interface {
    Close() error
}

// io.Seeker接口
type Seeker interface {
    Seek(offset int64, whence int) (int64, error)
}
```

这些接口通常与其他接口结合使用：

```go
// 组合使用Closer
type ReadCloser interface {
    Reader
    Closer
}

// 实际应用
file, err := os.Open("file.txt")
if err != nil {
    log.Fatal(err)
}
// file同时实现了Reader和Closer接口
defer file.Close()
```

#### 13.3.3 组合接口的使用

Go IO系统的强大之处在于接口的组合使用：

```go
// 常见的组合接口
type ReadWriter interface {
    Reader
    Writer
}

type ReadWriteCloser interface {
    Reader
    Writer
    Closer
}

type ReadSeeker interface {
    Reader
    Seeker
}

// 实际应用：读写压缩文件
file, err := os.Create("file.gz")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

// 创建gzip写入器
gzWriter := gzip.NewWriter(file)
defer gzWriter.Close()

// 向压缩文件写入数据
_, err = gzWriter.Write([]byte("压缩数据"))
if err != nil {
    log.Fatal(err)
}

// 读取压缩文件
file, err = os.Open("file.gz")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

gzReader, err := gzip.NewReader(file)
if err != nil {
    log.Fatal(err)
}
defer gzReader.Close()

// 从压缩文件读取数据
data, err := io.ReadAll(gzReader)
if err != nil {
    log.Fatal(err)
}
fmt.Println(string(data))
```

#### 13.3.4 自定义IO实现

自定义IO接口实现是高级Go编程的常见需求：

```go
// 自定义Reader示例：计数器Reader
type CountingReader struct {
    reader     io.Reader
    bytesRead  int64
}

func NewCountingReader(r io.Reader) *CountingReader {
    return &CountingReader{
        reader: r,
    }
}

func (r *CountingReader) Read(p []byte) (int, error) {
    n, err := r.reader.Read(p)
    r.bytesRead += int64(n)
    return n, err
}

func (r *CountingReader) BytesRead() int64 {
    return r.bytesRead
}

// 自定义Writer示例：多目标Writer
type MultiWriter struct {
    writers []io.Writer
}

func NewMultiWriter(writers ...io.Writer) *MultiWriter {
    return &MultiWriter{writers: writers}
}

func (w *MultiWriter) Write(p []byte) (int, error) {
    var firstErr error
    for _, writer := range w.writers {
        n, err := writer.Write(p)
        if err != nil && firstErr == nil {
            firstErr = err
        }
        if n != len(p) {
            return n, io.ErrShortWrite
        }
    }
    return len(p), firstErr
}
```

面试中的接口设计考点：
- Go的IO接口遵循单一职责原则，每个接口只做一件事
- 接口的组合优于继承，提供了更灵活的设计
- 实现自定义Reader/Writer时，需要严格遵守接口约定
- 了解标准库中常用的IO接口实现，如bufio、bytes、strings等包提供的类型

### 13.4 标准输入输出

#### 13.4.1 命令行参数处理

Go提供了flag包来处理命令行参数：

```go
package main

import (
    "flag"
    "fmt"
)

func main() {
    // 定义命令行参数
    namePtr := flag.String("name", "Guest", "用户名")
    agePtr := flag.Int("age", 0, "年龄")
    verbosePtr := flag.Bool("verbose", false, "是否输出详细信息")
    
    // 解析命令行参数
    flag.Parse()
    
    // 获取参数值
    fmt.Printf("Name: %s\n", *namePtr)
    fmt.Printf("Age: %d\n", *agePtr)
    fmt.Printf("Verbose: %t\n", *verbosePtr)
    
    // 获取非选项参数
    fmt.Println("未解析的参数:", flag.Args())
}
```

使用方式：
```bash
go run main.go -name "John" -age 30 -verbose file1.txt file2.txt
```

#### 13.4.2 标准输入输出重定向

Go程序可以轻松处理标准IO的重定向：

```go
// 从标准输入读取
scanner := bufio.NewScanner(os.Stdin)
fmt.Print("请输入文本: ")
if scanner.Scan() {
    input := scanner.Text()
    fmt.Printf("您输入的是: %s\n", input)
}

// 重定向标准输出
originalStdout := os.Stdout
file, err := os.Create("output.log")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

os.Stdout = file
fmt.Println("这行将写入文件")
os.Stdout = originalStdout
fmt.Println("这行将显示在终端")
```

#### 13.4.3 管道操作

Go可以方便地处理Unix管道：

```go
// 检查是否是管道输入
info, err := os.Stdin.Stat()
if err != nil {
    log.Fatal(err)
}
isPipe := (info.Mode() & os.ModeCharDevice) == 0

if isPipe {
    fmt.Println("从管道接收输入")
    data, err := io.ReadAll(os.Stdin)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("接收到数据: %s\n", data)
} else {
    fmt.Println("直接从终端接收输入")
}
```

运行示例：
```bash
echo "Hello from pipe" | go run main.go
```

#### 13.4.4 终端控制

Go可以通过多种方式实现终端控制：

```go
// 使用终端控制字符
fmt.Print("\033[31m这是红色文本\033[0m\n")
fmt.Print("\033[1m这是粗体文本\033[0m\n")
fmt.Print("\033[4m这是下划线文本\033[0m\n")

// 使用第三方库（如github.com/fatih/color）实现更丰富的终端控制
// 安装: go get github.com/fatih/color
/*
import "github.com/fatih/color"

// 创建颜色函数
red := color.New(color.FgRed).SprintFunc()
fmt.Printf("这个 %s 是红色的\n", red("词语"))

// 组合颜色属性
color.New(color.FgCyan, color.Bold).Println("粗体青色文本")
*/

// 终端大小获取
/*
import "golang.org/x/term"

width, height, err := term.GetSize(int(os.Stdout.Fd()))
if err != nil {
    log.Fatal(err)
}
fmt.Printf("终端大小: %d列 x %d行\n", width, height)
*/
```

面试中的标准IO考点：
- 理解os.Stdin、os.Stdout和os.Stderr的本质是实现了io.Reader或io.Writer接口的文件句柄
- 掌握如何检测程序输入是来自管道还是终端
- 了解如何重定向标准输入输出以实现日志记录或测试

### 13.5 目录操作

Go提供了完整的目录操作功能，支持目录的创建、遍历、监控等操作。

#### 13.5.1 目录遍历和搜索

```go
// 列出目录内容
func listDirectory(path string) error {
    entries, err := os.ReadDir(path)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        fileInfo, err := entry.Info()
        if err != nil {
            continue
        }
        
        fileType := "文件"
        if entry.IsDir() {
            fileType = "目录"
        }
        
        fmt.Printf("%s - %s - %d字节 - %s\n", 
            entry.Name(), 
            fileType, 
            fileInfo.Size(),
            fileInfo.ModTime().Format("2006-01-02 15:04:05"))
    }
    return nil
}

// 递归遍历目录
func walkDirectory(path string) error {
    return filepath.WalkDir(path, func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            fmt.Printf("访问路径错误 %s: %v\n", path, err)
            return err
        }
        
        if d.IsDir() {
            fmt.Printf("目录: %s\n", path)
        } else {
            info, err := d.Info()
            if err != nil {
                return err
            }
            fmt.Printf("文件: %s (%d字节)\n", path, info.Size())
        }
        return nil
    })
}

// 搜索特定类型文件
func findFiles(root, pattern string) ([]string, error) {
    var matches []string
    err := filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            return err
        }
        if !d.IsDir() && strings.HasSuffix(d.Name(), pattern) {
            matches = append(matches, path)
        }
        return nil
    })
    return matches, err
}
```

#### 13.5.2 文件树操作

```go
// 创建目录
err := os.Mkdir("newdir", 0755)
if err != nil {
    log.Fatal(err)
}

// 创建多级目录
err = os.MkdirAll("path/to/nested/directory", 0755)
if err != nil {
    log.Fatal(err)
}

// 删除空目录
err = os.Remove("emptydir")
if err != nil {
    log.Fatal(err)
}

// 递归删除目录及内容
err = os.RemoveAll("directory")
if err != nil {
    log.Fatal(err)
}

// 重命名/移动目录
err = os.Rename("olddir", "newdir")
if err != nil {
    log.Fatal(err)
}

// 复制目录树
func copyDir(src, dst string) error {
    // 获取源目录信息
    srcInfo, err := os.Stat(src)
    if err != nil {
        return err
    }
    
    // 创建目标目录
    err = os.MkdirAll(dst, srcInfo.Mode())
    if err != nil {
        return err
    }
    
    // 遍历源目录
    entries, err := os.ReadDir(src)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        srcPath := filepath.Join(src, entry.Name())
        dstPath := filepath.Join(dst, entry.Name())
        
        if entry.IsDir() {
            // 递归复制子目录
            err = copyDir(srcPath, dstPath)
            if err != nil {
                return err
            }
        } else {
            // 复制文件
            err = copyFile(srcPath, dstPath)
            if err != nil {
                return err
            }
        }
    }
    
    return nil
}

// 辅助函数：复制文件
func copyFile(src, dst string) error {
    srcFile, err := os.Open(src)
    if err != nil {
        return err
    }
    defer srcFile.Close()
    
    srcInfo, err := srcFile.Stat()
    if err != nil {
        return err
    }
    
    dstFile, err := os.OpenFile(dst, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, srcInfo.Mode())
    if err != nil {
        return err
    }
    defer dstFile.Close()
    
    _, err = io.Copy(dstFile, srcFile)
    return err
}
```

#### 13.5.3 监控文件系统变化

Go没有内置的文件系统监控功能，但可以使用第三方库如`fsnotify`：

```go
// 使用fsnotify监控目录变化
// 安装: go get github.com/fsnotify/fsnotify
/*
import "github.com/fsnotify/fsnotify"

func watchDirectory(path string) error {
    watcher, err := fsnotify.NewWatcher()
    if err != nil {
        return err
    }
    defer watcher.Close()
    
    // 启动监听协程
    go func() {
        for {
            select {
            case event, ok := <-watcher.Events:
                if !ok {
                    return
                }
                fmt.Printf("事件: %s %s\n", event.Name, event.Op)
                
                if event.Op&fsnotify.Write == fsnotify.Write {
                    fmt.Printf("文件已修改: %s\n", event.Name)
                }
                if event.Op&fsnotify.Create == fsnotify.Create {
                    fmt.Printf("文件已创建: %s\n", event.Name)
                }
                if event.Op&fsnotify.Remove == fsnotify.Remove {
                    fmt.Printf("文件已删除: %s\n", event.Name)
                }
                
            case err, ok := <-watcher.Errors:
                if !ok {
                    return
                }
                fmt.Printf("监控错误: %v\n", err)
            }
        }
    }()
    
    // 添加监控路径
    err = watcher.Add(path)
    if err != nil {
        return err
    }
    
    // 阻塞主线程
    <-make(chan struct{})
    return nil
}
*/
```

#### 13.5.4 批量文件处理

```go
// 批量重命名文件
func batchRename(dir, oldPattern, newPattern string) error {
    entries, err := os.ReadDir(dir)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        oldName := entry.Name()
        if strings.Contains(oldName, oldPattern) {
            newName := strings.ReplaceAll(oldName, oldPattern, newPattern)
            oldPath := filepath.Join(dir, oldName)
            newPath := filepath.Join(dir, newName)
            
            err := os.Rename(oldPath, newPath)
            if err != nil {
                return err
            }
            fmt.Printf("已重命名: %s -> %s\n", oldName, newName)
        }
    }
    return nil
}

// 批量处理文件内容
func processFiles(dir, pattern string, processor func([]byte) []byte) error {
    matches, err := filepath.Glob(filepath.Join(dir, pattern))
    if err != nil {
        return err
    }
    
    for _, match := range matches {
        data, err := os.ReadFile(match)
        if err != nil {
            return err
        }
        
        processed := processor(data)
        
        err = os.WriteFile(match, processed, 0644)
        if err != nil {
            return err
        }
        fmt.Printf("已处理文件: %s\n", match)
    }
    return nil
}

// 示例处理函数：将文本转为大写
func toUpperProcessor(data []byte) []byte {
    return bytes.ToUpper(data)
}
```

面试中的目录操作考点：
- 了解如何高效递归遍历大型目录树
- 掌握使用`filepath.WalkDir`和`os.ReadDir`的区别和适用场景
- 理解文件系统监控的实现方式和性能考量
- 掌握并发批处理文件的最佳实践

### 13.6 特殊文件格式处理

Go标准库提供了丰富的特殊文件格式处理能力，支持常见的结构化数据格式。

#### 13.6.1 JSON文件读写

JSON是最常用的数据交换格式之一：

```go
// 定义结构体
type Person struct {
    Name    string   `json:"name"`
    Age     int      `json:"age"`
    Email   string   `json:"email,omitempty"`
    Hobbies []string `json:"hobbies"`
}

// 结构体转JSON
person := Person{
    Name:    "张三",
    Age:     30,
    Email:   "zhangsan@example.com",
    Hobbies: []string{"阅读", "旅行", "摄影"},
}

// 编码为JSON
data, err := json.MarshalIndent(person, "", "  ")
if err != nil {
    log.Fatal(err)
}
fmt.Println(string(data))

// 写入JSON文件
err = os.WriteFile("person.json", data, 0644)
if err != nil {
    log.Fatal(err)
}

// 读取JSON文件
fileData, err := os.ReadFile("person.json")
if err != nil {
    log.Fatal(err)
}

// JSON转结构体
var newPerson Person
err = json.Unmarshal(fileData, &newPerson)
if err != nil {
    log.Fatal(err)
}
fmt.Printf("解析的人员: %+v\n", newPerson)

// 流式处理JSON
file, err := os.Create("people.json")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

encoder := json.NewEncoder(file)
encoder.SetIndent("", "  ")

// 编码多个对象
people := []Person{
    {Name: "张三", Age: 30},
    {Name: "李四", Age: 25},
    {Name: "王五", Age: 35},
}

for _, p := range people {
    err := encoder.Encode(p)
    if err != nil {
        log.Fatal(err)
    }
}
```

#### 13.6.2 CSV文件处理

CSV是表格数据交换的常用格式：

```go
// 写入CSV
file, err := os.Create("data.csv")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

writer := csv.NewWriter(file)
defer writer.Flush()

// 写入标题行
header := []string{"姓名", "年龄", "邮箱"}
err = writer.Write(header)
if err != nil {
    log.Fatal(err)
}

// 写入数据行
records := [][]string{
    {"张三", "30", "zhangsan@example.com"},
    {"李四", "25", "lisi@example.com"},
    {"王五", "35", "wangwu@example.com"},
}

for _, record := range records {
    err := writer.Write(record)
    if err != nil {
        log.Fatal(err)
    }
}

// 读取CSV
file, err = os.Open("data.csv")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

reader := csv.NewReader(file)

// 读取所有记录
records, err = reader.ReadAll()
if err != nil {
    log.Fatal(err)
}

for i, record := range records {
    fmt.Printf("行 %d: %v\n", i, record)
}

// 逐行读取大型CSV
file, err = os.Open("large.csv")
if err != nil {
    log.Fatal(err)
}
defer file.Close()

reader = csv.NewReader(file)

// 设置字段分隔符（如果不是逗号）
reader.Comma = ';'

// 是否懒惰引号处理
reader.LazyQuotes = true

lineCount := 0
for {
    record, err := reader.Read()
    if err == io.EOF {
        break
    }
    if err != nil {
        log.Fatal(err)
    }
    
    lineCount++
    // 处理记录...
}
fmt.Printf("总共读取了%d行\n", lineCount)
```

#### 13.6.3 XML文件操作

XML是另一种常见的结构化数据格式：

```go
// 定义XML结构
type Book struct {
    XMLName xml.Name `xml:"book"`
    ID      string   `xml:"id,attr"`
    Title   string   `xml:"title"`
    Author  string   `xml:"author"`
    Year    int      `xml:"year"`
    Price   float64  `xml:"price"`
}

type Library struct {
    XMLName xml.Name `xml:"library"`
    Books   []Book   `xml:"book"`
}

// 创建XML数据
library := Library{
    Books: []Book{
        {
            ID:     "b001",
            Title:  "Go编程实战",
            Author: "张三",
            Year:   2021,
            Price:  59.9,
        },
        {
            ID:     "b002",
            Title:  "微服务架构设计",
            Author: "李四",
            Year:   2020,
            Price:  69.9,
        },
    },
}

// 编码为XML
data, err := xml.MarshalIndent(library, "", "  ")
if err != nil {
    log.Fatal(err)
}

// 添加XML头
xmlData := []byte(xml.Header + string(data))

// 写入文件
err = os.WriteFile("library.xml", xmlData, 0644)
if err != nil {
    log.Fatal(err)
}

// 读取XML文件
fileData, err := os.ReadFile("library.xml")
if err != nil {
    log.Fatal(err)
}

// 解码XML
var newLibrary Library
err = xml.Unmarshal(fileData, &newLibrary)
if err != nil {
    log.Fatal(err)
}

// 处理解码后的数据
for _, book := range newLibrary.Books {
    fmt.Printf("书籍: %s (作者: %s, 价格: %.2f)\n", 
        book.Title, book.Author, book.Price)
}
```

#### 13.6.4 二进制文件处理

Go提供了多种处理二进制数据的方法：

```go
// 使用encoding/binary包处理二进制数据
type BinaryData struct {
    ID        uint32
    Timestamp int64
    Value     float64
    Flag      byte
}

// 写入二进制文件
func writeBinaryFile(filename string, data []BinaryData) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    for _, item := range data {
        // 写入uint32
        err = binary.Write(file, binary.LittleEndian, item.ID)
        if err != nil {
            return err
        }
        
        // 写入int64
        err = binary.Write(file, binary.LittleEndian, item.Timestamp)
        if err != nil {
            return err
        }
        
        // 写入float64
        err = binary.Write(file, binary.LittleEndian, item.Value)
        if err != nil {
            return err
        }
        
        // 写入byte
        err = binary.Write(file, binary.LittleEndian, item.Flag)
        if err != nil {
            return err
        }
    }
    
    return nil
}

// 读取二进制文件
func readBinaryFile(filename string) ([]BinaryData, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()
    
    // 获取文件大小
    fileInfo, err := file.Stat()
    if err != nil {
        return nil, err
    }
    
    // 计算记录数（每条记录的大小为ID(4) + Timestamp(8) + Value(8) + Flag(1) = 21字节）
    recordSize := 4 + 8 + 8 + 1
    recordCount := fileInfo.Size() / int64(recordSize)
    
    var result []BinaryData
    for i := int64(0); i < recordCount; i++ {
        var item BinaryData
        
        // 读取uint32
        err = binary.Read(file, binary.LittleEndian, &item.ID)
        if err != nil {
            return nil, err
        }
        
        // 读取int64
        err = binary.Read(file, binary.LittleEndian, &item.Timestamp)
        if err != nil {
            return nil, err
        }
        
        // 读取float64
        err = binary.Read(file, binary.LittleEndian, &item.Value)
        if err != nil {
            return nil, err
        }
        
        // 读取byte
        err = binary.Read(file, binary.LittleEndian, &item.Flag)
        if err != nil {
            return nil, err
        }
        
        result = append(result, item)
    }
    
    return result, nil
}

// 使用gob包序列化Go数据结构
func saveGobData(filename string, data interface{}) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    encoder := gob.NewEncoder(file)
    return encoder.Encode(data)
}

func loadGobData(filename string, data interface{}) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    decoder := gob.NewDecoder(file)
    return decoder.Decode(data)
}
```

面试中的文件格式处理考点：
- 理解JSON标签的使用和自定义编组/解组方法
- 掌握大型CSV文件的高效处理方法
- 了解XML命名空间处理和自定义XML解析
- 熟悉二进制数据的字节序(Endianness)和对齐问题

### 13.7 高性能IO技巧

要实现高性能的文件操作，需要理解IO的底层原理和Go语言的优化技术。

#### 13.7.1 内存映射文件

内存映射文件允许将文件直接映射到进程的地址空间，提供了更高效的读写操作：

```go
// 安装: go get golang.org/x/exp/mmap
/*
import "golang.org/x/exp/mmap"

// 只读内存映射
func readWithMmap(filename string) error {
    // 打开内存映射文件
    reader, err := mmap.Open(filename)
    if err != nil {
        return err
    }
    defer reader.Close()
    
    // 获取文件大小
    size := reader.Len()
    fmt.Printf("文件大小: %d字节\n", size)
    
    // 读取部分数据
    data := make([]byte, 100)
    n, err := reader.ReadAt(data, 0)
    if err != nil && err != io.EOF {
        return err
    }
    
    fmt.Printf("读取了%d字节: %s\n", n, data[:n])
    return nil
}
*/

// 直接使用syscall实现内存映射
/*
import (
    "os"
    "reflect"
    "syscall"
    "unsafe"
)

func mapFile(filename string) ([]byte, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()
    
    fileInfo, err := file.Stat()
    if err != nil {
        return nil, err
    }
    
    size := fileInfo.Size()
    if size == 0 {
        return nil, nil
    }
    
    // 映射文件到内存
    data, err := syscall.Mmap(int(file.Fd()), 0, int(size), syscall.PROT_READ, syscall.MAP_SHARED)
    if err != nil {
        return nil, err
    }
    
    return data, nil
}

func unmapFile(data []byte) error {
    // 获取切片的头部信息
    header := *(*reflect.SliceHeader)(unsafe.Pointer(&data))
    // 解除映射
    return syscall.Munmap(data)
}
*/
```

#### 13.7.2 异步IO操作

Go天然支持并发IO操作，通过goroutine可以实现高效的异步IO：

```go
// 异步读取多个文件
func readFilesAsync(filenames []string) ([][]byte, []error) {
    type result struct {
        data []byte
        err  error
        idx  int
    }
    
    // 创建通道接收结果
    ch := make(chan result, len(filenames))
    
    // 启动goroutine并发读取文件
    for i, filename := range filenames {
        go func(idx int, fname string) {
            data, err := os.ReadFile(fname)
            ch <- result{data, err, idx}
        }(i, filename)
    }
    
    // 收集结果
    contents := make([][]byte, len(filenames))
    errors := make([]error, len(filenames))
    
    for range filenames {
        res := <-ch
        contents[res.idx] = res.data
        errors[res.idx] = res.err
    }
    
    return contents, errors
}

// 并发处理大文件
func processLargeFileAsync(filename string, numWorkers int, processor func([]byte)) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // 获取文件大小
    fileInfo, err := file.Stat()
    if err != nil {
        return err
    }
    
    fileSize := fileInfo.Size()
    chunkSize := fileSize / int64(numWorkers)
    
    // 创建工作通道
    type chunk struct {
        offset int64
        data   []byte
    }
    jobs := make(chan chunk, numWorkers)
    results := make(chan error, numWorkers)
    
    // 启动工作协程
    for i := 0; i < numWorkers; i++ {
        go func() {
            for job := range jobs {
                // 处理数据块
                processor(job.data)
                results <- nil
            }
        }()
    }
    
    // 读取文件并分发任务
    var offset int64
    for i := 0; i < numWorkers; i++ {
        // 计算当前块的实际大小
        size := chunkSize
        if i == numWorkers-1 {
            size = fileSize - offset // 最后一块可能大小不同
        }
        
        // 读取块数据
        data := make([]byte, size)
        n, err := file.ReadAt(data, offset)
        if err != nil && err != io.EOF {
            return err
        }
        
        // 发送任务
        jobs <- chunk{offset, data[:n]}
        offset += int64(n)
    }
    
    // 关闭任务通道
    close(jobs)
    
    // 等待所有结果
    for i := 0; i < numWorkers; i++ {
        if err := <-results; err != nil {
            return err
        }
    }
    
    return nil
}
```

#### 13.7.3 IO多路复用

IO多路复用允许一个进程同时监控多个文件描述符：

```go
// 使用select实现简单的IO多路复用
func multiIOExample() {
    file1 := openFileAsync("file1.txt")
    file2 := openFileAsync("file2.txt")
    file3 := openFileAsync("file3.txt")
    
    select {
    case data := <-file1:
        fmt.Println("File1 ready:", string(data))
    case data := <-file2:
        fmt.Println("File2 ready:", string(data))
    case data := <-file3:
        fmt.Println("File3 ready:", string(data))
    case <-time.After(5 * time.Second):
        fmt.Println("Timeout waiting for files")
    }
}

// 异步打开文件
func openFileAsync(filename string) <-chan []byte {
    result := make(chan []byte)
    go func() {
        data, err := os.ReadFile(filename)
        if err != nil {
            close(result)
            return
        }
        result <- data
    }()
    return result
}

// 多路读取示例
func multiReaderExample() {
    r1 := strings.NewReader("first reader ")
    r2 := strings.NewReader("second reader ")
    r3 := strings.NewReader("third reader\n")
    
    // 创建多读取器
    mr := io.MultiReader(r1, r2, r3)
    
    // 从多个读取器顺序读取
    if _, err := io.Copy(os.Stdout, mr); err != nil {
        log.Fatal(err)
    }
}
```

#### 13.7.4 零拷贝技术

零拷贝是一种避免CPU不必要的数据拷贝以提高性能的技术：

```go
// 使用io.Copy实现零拷贝
func zeroCopyExample(src, dst string) error {
    source, err := os.Open(src)
    if err != nil {
        return err
    }
    defer source.Close()
    
    destination, err := os.Create(dst)
    if err != nil {
        return err
    }
    defer destination.Close()
    
    // io.Copy内部使用操作系统的零拷贝机制（如sendfile）
    bytesWritten, err := io.Copy(destination, source)
    if err != nil {
        return err
    }
    
    fmt.Printf("复制了%d字节，零拷贝模式\n", bytesWritten)
    return nil
}

// 实现简单的管道，避免中间缓冲区
func pipeExample() error {
    r, w := io.Pipe()
    
    // 写入协程
    go func() {
        defer w.Close()
        for i := 0; i < 10; i++ {
            fmt.Fprintf(w, "数据块 %d\n", i)
            time.Sleep(100 * time.Millisecond)
        }
    }()
    
    // 读取协程（主协程）
    scanner := bufio.NewScanner(r)
    for scanner.Scan() {
        fmt.Printf("读取: %s\n", scanner.Text())
    }
    
    return scanner.Err()
}
```

性能优化的关键考点：
- 理解操作系统的缓存机制与Go的缓冲IO关系
- 掌握不同IO模式（同步、异步、内存映射）的适用场景
- 学会使用profiling工具诊断IO瓶颈
- 避免不必要的数据复制和转换
- 合理使用并发提高IO吞吐量

### 13.8 错误处理和资源管理

文件操作中的错误处理和资源管理至关重要，尤其是在高并发的服务端程序中。

#### 13.8.1 文件操作错误处理

```go
// 基本错误处理模式
func basicErrorHandling() {
    file, err := os.Open("nonexistent.txt")
    if err != nil {
        // 检查特定错误类型
        if os.IsNotExist(err) {
            fmt.Println("文件不存在")
        } else if os.IsPermission(err) {
            fmt.Println("权限不足")
        } else {
            fmt.Printf("未知错误: %v\n", err)
        }
        return
    }
    defer file.Close()
    
    // 处理特定的IO错误
    data := make([]byte, 100)
    n, err := file.Read(data)
    if err != nil {
        if err == io.EOF {
            fmt.Println("已读取到文件末尾")
        } else {
            fmt.Printf("读取错误: %v\n", err)
        }
        return
    }
    
    fmt.Printf("读取了%d字节\n", n)
}

// 使用errors.Is和errors.As处理错误（Go 1.13+）
func modernErrorHandling() {
    _, err := os.Open("nonexistent.txt")
    if err != nil {
        var pathError *os.PathError
        if errors.As(err, &pathError) {
            fmt.Printf("路径错误: %v\n", pathError.Path)
        }
        
        if errors.Is(err, os.ErrNotExist) {
            fmt.Println("文件不存在")
        }
    }
}

// 自定义IO错误类型
type FileProcessError struct {
    Path string
    Op   string
    Err  error
}

func (e *FileProcessError) Error() string {
    return fmt.Sprintf("操作 %s 文件 %s 失败: %v", e.Op, e.Path, e.Err)
}

func (e *FileProcessError) Unwrap() error {
    return e.Err
}

// 使用自定义错误
func processWithCustomError(path string) error {
    file, err := os.Open(path)
    if err != nil {
        return &FileProcessError{Path: path, Op: "open", Err: err}
    }
    defer file.Close()
    
    data, err := io.ReadAll(file)
    if err != nil {
        return &FileProcessError{Path: path, Op: "read", Err: err}
    }
    
    err = processData(data)
    if err != nil {
        return &FileProcessError{Path: path, Op: "process", Err: err}
    }
    
    return nil
}
```

#### 13.8.2 资源泄漏预防

```go
// 使用defer确保资源释放
func safeFileOperation(path string) ([]byte, error) {
    file, err := os.Open(path)
    if err != nil {
        return nil, err
    }
    // 即使后续代码发生panic，也能确保文件关闭
    defer file.Close()
    
    return io.ReadAll(file)
}

// 嵌套defer的执行顺序
func nestedDefers() {
    fmt.Println("开始函数")
    defer fmt.Println("第一层defer")
    
    if true {
        defer fmt.Println("第二层defer")
        fmt.Println("条件块内部")
    }
    
    defer fmt.Println("第三层defer")
    fmt.Println("函数结束")
}
// 输出顺序:
// 开始函数
// 条件块内部
// 函数结束
// 第三层defer
// 第二层defer
// 第一层defer

// 关闭多个资源
func multipleResources() error {
    srcFile, err := os.Open("source.txt")
    if err != nil {
        return err
    }
    defer srcFile.Close()
    
    dstFile, err := os.Create("destination.txt")
    if err != nil {
        return err
    }
    defer dstFile.Close()
    
    // 创建缓冲写入器
    writer := bufio.NewWriter(dstFile)
    defer writer.Flush() // 确保缓冲数据写入磁盘
    
    // 使用资源
    _, err = io.Copy(writer, srcFile)
    return err
}
```

#### 13.8.3 defer的正确使用

```go
// defer与函数参数求值
func deferEvaluation() {
    i := 1
    defer fmt.Println("defer i =", i) // 输出: defer i = 1
    i++
    fmt.Println("函数中 i =", i) // 输出: 函数中 i = 2
}

// defer与命名返回值
func deferWithNamedReturn() (result int) {
    defer func() {
        result *= 2 // 修改命名返回值
    }()
    return 5 // 返回10而不是5
}

// defer执行顺序
func deferOrder() {
    for i := 0; i < 5; i++ {
        defer fmt.Printf("%d ", i) // 输出: 4 3 2 1 0
    }
}

// 避免在循环中错误使用defer
func wrongDeferInLoop() error {
    files := []string{"file1.txt", "file2.txt", "file3.txt"}
    
    for _, filename := range files {
        file, err := os.Open(filename)
        if err != nil {
            return err
        }
        // 错误：所有文件会在函数结束时才关闭
        defer file.Close()
        
        // 处理文件...
    }
    return nil
}

// 正确做法：将defer封装在函数中
func correctDeferInLoop() error {
    files := []string{"file1.txt", "file2.txt", "file3.txt"}
    
    for _, filename := range files {
        if err := processFile(filename); err != nil {
            return err
        }
    }
    return nil
}

func processFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close() // 正确：在processFile返回时关闭
    
    // 处理文件...
    return nil
}
```

#### 13.8.4 异常恢复机制

```go
// 使用recover捕获panic
func safeIOOperation() (err error) {
    defer func() {
        if r := recover(); r != nil {
            err = fmt.Errorf("IO操作panic: %v", r)
        }
    }()
    
    // 可能引发panic的操作
    performRiskyIO()
    return nil
}

// recover的最佳实践
func recoverExample() {
    defer func() {
        if r := recover(); r != nil {
            // 记录panic信息
            fmt.Printf("捕获到panic: %v\n", r)
            
            // 获取堆栈跟踪
            debug.PrintStack()
            
            // 转换为错误返回给调用方
            // 或者执行清理工作
        }
    }()
    
    // 可能导致panic的代码
}

// 有选择性地恢复panic
func selectiveRecover() {
    defer func() {
        if r := recover(); r != nil {
            switch err := r.(type) {
            case *os.PathError:
                fmt.Printf("捕获到文件路径错误: %v\n", err)
            case error:
                if strings.Contains(err.Error(), "预期的错误") {
                    fmt.Println("捕获到预期的错误")
                } else {
                    // 对于意外错误，重新触发panic
                    panic(r)
                }
            default:
                panic(r) // 重新触发未知类型的panic
            }
        }
    }()
    
    // 可能导致panic的代码
}
```

面试中的错误处理考点：
- 理解和正确使用defer的机制和执行顺序
- 掌握错误处理的设计模式和最佳实践
- 理解panic和recover的适用场景和使用限制
- 了解如何在并发环境中安全处理文件资源

## 面试要点

1. **GO语言IO接口的设计理念**
   - IO接口设计遵循单一职责原则，接口小而专一
   - 组合接口实现更复杂功能，而非继承
   - 标准库中的io、io/ioutil、bufio等包的关系和使用场景
   - Reader和Writer接口在各种IO操作中的统一应用

2. **文件操作的最佳实践**
   - 正确使用defer确保资源释放
   - 合理处理文件操作错误
   - 路径处理的跨平台兼容性考虑
   - 使用bufio提高小块读写性能

3. **大文件处理的性能优化**
   - 分块读取避免内存溢出
   - 使用内存映射提高访问速度
   - 并发处理数据块加速处理
   - 流式处理避免全部加载到内存

4. **跨平台文件操作的注意事项**
   - 使用filepath包处理路径分隔符
   - 文件权限和属性的平台差异
   - 换行符处理(\r\n vs \n)
   - 文件锁定机制的平台差异

5. **内存映射文件的使用场景**
   - 适用于频繁随机访问的大文件
   - 数据库实现中的应用
   - 与传统IO的性能对比
   - 内存映射的限制和风险

6. **IO操作的错误处理策略**
   - 区分预期错误和非预期错误
   - 错误传播和封装最佳实践
   - 优雅降级和失败恢复策略
   - 超时和取消操作的实现

7. **高级IO技术的应用**
   - 零拷贝技术的原理和实现
   - IO多路复用的使用场景
   - 异步IO与goroutine的结合
   - 网络IO与文件IO的区别和联系

## 实践练习

### 1. 实现一个文件复制工具

**要求**:
- 支持大文件高效复制
- 实现进度显示功能
- 支持断点续传
- 提供校验和验证

**示例框架**:
```go
package main

import (
    "flag"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "time"
)

func main() {
    // 解析命令行参数
    srcFile := flag.String("src", "", "源文件路径")
    dstFile := flag.String("dst", "", "目标文件路径")
    bufSize := flag.Int("buf", 8192, "缓冲区大小(KB)")
    resume := flag.Bool("resume", false, "启用断点续传")
    flag.Parse()
    
    // 检查参数
    if *srcFile == "" || *dstFile == "" {
        flag.Usage()
        return
    }
    
    // 执行复制
    err := copyFile(*srcFile, *dstFile, *bufSize*1024, *resume)
    if err != nil {
        fmt.Fprintf(os.Stderr, "复制失败: %v\n", err)
        os.Exit(1)
    }
    
    fmt.Println("复制完成!")
}

func copyFile(src, dst string, bufferSize int, resume bool) error {
    // 实现文件复制逻辑
    // 1. 打开源文件
    // 2. 创建或打开目标文件
    // 3. 如果支持断点续传，确定起始位置
    // 4. 分块复制并显示进度
    // 5. 完成后进行校验
    return nil
}

**核心实现**:

```go
package main

import (
    "crypto/md5"
    "flag"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "time"
)

func main() {
    srcFile := flag.String("src", "", "源文件路径")
    dstFile := flag.String("dst", "", "目标文件路径")
    bufSize := flag.Int("buf", 8192, "缓冲区大小(KB)")
    resume := flag.Bool("resume", false, "启用断点续传")
    verify := flag.Bool("verify", true, "复制后验证文件")
    flag.Parse()
    
    if *srcFile == "" || *dstFile == "" {
        flag.Usage()
        return
    }
    
    err := copyFile(*srcFile, *dstFile, *bufSize*1024, *resume, *verify)
    if err != nil {
        fmt.Fprintf(os.Stderr, "复制失败: %v\n", err)
        os.Exit(1)
    }
    
    fmt.Println("复制完成!")
}

func copyFile(src, dst string, bufferSize int, resume, verify bool) error {
    // 1. 打开源文件
    srcFile, err := os.Open(src)
    if err != nil {
        return fmt.Errorf("无法打开源文件: %w", err)
    }
    defer srcFile.Close()
    
    // 获取源文件信息
    srcInfo, err := srcFile.Stat()
    if err != nil {
        return fmt.Errorf("无法获取源文件信息: %w", err)
    }
    
    totalSize := srcInfo.Size()
    
    // 检查目标文件是否存在
    var startPos int64 = 0
    if resume {
        if dstInfo, err := os.Stat(dst); err == nil {
            startPos = dstInfo.Size()
            if startPos >= totalSize {
                fmt.Println("文件已完全复制，无需继续")
                return nil
            }
            
            fmt.Printf("断点续传：从位置 %d/%d 开始复制\n", startPos, totalSize)
        }
    }
    
    // 2. 创建或打开目标文件
    flag := os.O_CREATE | os.O_WRONLY
    if resume {
        flag |= os.O_APPEND
    } else {
        flag |= os.O_TRUNC
    }
    
    dstFile, err := os.OpenFile(dst, flag, srcInfo.Mode())
    if err != nil {
        return fmt.Errorf("无法创建目标文件: %w", err)
    }
    defer dstFile.Close()
    
    // 3. 如果支持断点续传，确定起始位置
    if startPos > 0 {
        _, err = srcFile.Seek(startPos, io.SeekStart)
        if err != nil {
            return fmt.Errorf("无法设置源文件位置: %w", err)
        }
    }
    
    // 4. 分块复制并显示进度
    buffer := make([]byte, bufferSize)
    copied := startPos
    lastProgressUpdate := time.Now()
    startTime := time.Now()
    
    for {
        // 读取一块数据
        n, err := srcFile.Read(buffer)
        if err != nil && err != io.EOF {
            return fmt.Errorf("读取源文件错误: %w", err)
        }
        
        if n == 0 { // 文件已完全读取
            break
        }
        
        // 写入目标文件
        if _, err := dstFile.Write(buffer[:n]); err != nil {
            return fmt.Errorf("写入目标文件错误: %w", err)
        }
        
        // 更新复制进度
        copied += int64(n)
        
        // 定期更新进度（每秒一次）
        if time.Since(lastProgressUpdate) > time.Second {
            percent := float64(copied) / float64(totalSize) * 100
            speed := float64(copied-startPos) / time.Since(startTime).Seconds() / 1024 / 1024
            fmt.Printf("\r进度: %.2f%% (%.2f MB/s)", percent, speed)
            lastProgressUpdate = time.Now()
        }
    }
    
    // 最终进度
    fmt.Printf("\r进度: 100.00%% (复制了 %d 字节) 耗时: %v\n", copied, time.Since(startTime))
    
    // 5. 完成后进行校验
    if verify {
        fmt.Println("正在验证文件...")
        srcChecksum, err := calculateMD5(src)
        if err != nil {
            return fmt.Errorf("计算源文件校验和失败: %w", err)
        }
        
        dstChecksum, err := calculateMD5(dst)
        if err != nil {
            return fmt.Errorf("计算目标文件校验和失败: %w", err)
        }
        
        if srcChecksum != dstChecksum {
            return fmt.Errorf("文件校验失败，校验和不匹配")
        }
        
        fmt.Println("文件验证成功，校验和匹配")
    }
    
    return nil
}

// 计算文件MD5校验和
func calculateMD5(filePath string) (string, error) {
    file, err := os.Open(filePath)
    if err != nil {
        return "", err
    }
    defer file.Close()
    
    hash := md5.New()
    if _, err := io.Copy(hash, file); err != nil {
        return "", err
    }
    
    return fmt.Sprintf("%x", hash.Sum(nil)), nil
}
```

### 2. 编写日志文件轮转程序

**要求**:
- 按大小或时间自动轮转日志文件
- 保留指定数量的历史日志
- 支持压缩归档
- 优雅处理并发写入

**核心实现**:

```go
package main

import (
    "compress/gzip"
    "flag"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "sort"
    "strconv"
    "strings"
    "sync"
    "time"
)

// 日志轮转器配置
type LogRotator struct {
    LogPath      string        // 日志文件路径
    MaxSize      int64         // 最大文件大小(字节)
    MaxAge       time.Duration // 最大文件寿命
    MaxBackups   int           // 保留的最大备份数量
    Compress     bool          // 是否压缩旧日志
    RotateByTime bool          // 是否按时间轮转

    file     *os.File   // 当前日志文件
    size     int64      // 当前文件大小
    created  time.Time  // 文件创建时间
    mu       sync.Mutex // 保护文件操作的互斥锁
    interval time.Duration // 检查轮转的时间间隔
}

// 创建新的日志轮转器
func NewLogRotator(logPath string, maxSize int64, maxAge time.Duration, maxBackups int, compress, rotateByTime bool) (*LogRotator, error) {
    r := &LogRotator{
        LogPath:      logPath,
        MaxSize:      maxSize,
        MaxAge:       maxAge,
        MaxBackups:   maxBackups,
        Compress:     compress,
        RotateByTime: rotateByTime,
        interval:     10 * time.Second, // 默认10秒检查一次
    }

    // 打开或创建日志文件
    if err := r.openFile(); err != nil {
        return nil, err
    }

    // 启动自动轮转检查
    go r.autoRotate()

    return r, nil
}

// 打开日志文件
func (r *LogRotator) openFile() error {
    r.mu.Lock()
    defer r.mu.Unlock()

    // 检查文件是否存在
    info, err := os.Stat(r.LogPath)
    if err == nil {
        // 文件存在，获取当前大小和创建时间
        r.size = info.Size()
        r.created = info.ModTime()
    } else if os.IsNotExist(err) {
        // 文件不存在，创建目录
        dir := filepath.Dir(r.LogPath)
        if err = os.MkdirAll(dir, 0755); err != nil {
            return fmt.Errorf("无法创建日志目录: %w", err)
        }
        r.size = 0
        r.created = time.Now()
    } else {
        return fmt.Errorf("检查日志文件失败: %w", err)
    }

    // 打开或创建文件
    file, err := os.OpenFile(r.LogPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
    if err != nil {
        return fmt.Errorf("无法打开日志文件: %w", err)
    }

    r.file = file
    return nil
}

// 写入日志
func (r *LogRotator) Write(p []byte) (n int, err error) {
    r.mu.Lock()
    defer r.mu.Unlock()

    // 检查是否需要轮转
    if r.shouldRotate() {
        if err := r.rotate(); err != nil {
            return 0, fmt.Errorf("轮转日志失败: %w", err)
        }
    }

    // 写入日志
    n, err = r.file.Write(p)
    r.size += int64(n)
    return n, err
}

// 关闭日志
func (r *LogRotator) Close() error {
    r.mu.Lock()
    defer r.mu.Unlock()

    if r.file != nil {
        return r.file.Close()
    }
    return nil
}

// 检查是否需要轮转
func (r *LogRotator) shouldRotate() bool {
    if r.file == nil {
        return false
    }

    // 检查大小
    if r.MaxSize > 0 && r.size >= r.MaxSize {
        return true
    }

    // 检查时间
    if r.RotateByTime && r.MaxAge > 0 && time.Since(r.created) >= r.MaxAge {
        return true
    }

    return false
}

// 执行日志轮转
func (r *LogRotator) rotate() error {
    // 关闭当前文件
    if r.file != nil {
        if err := r.file.Close(); err != nil {
            return err
        }
        r.file = nil
    }

    // 生成备份文件名
    backupName := r.backupName()
    
    // 重命名当前日志文件为备份文件
    if err := os.Rename(r.LogPath, backupName); err != nil && !os.IsNotExist(err) {
        return fmt.Errorf("重命名日志文件失败: %w", err)
    }

    // 打开新的日志文件
    if err := r.openFile(); err != nil {
        return err
    }

    // 压缩旧日志文件（异步进行）
    if r.Compress {
        go r.compressLogFile(backupName)
    }

    // 清理旧日志
    go r.cleanup()

    return nil
}

// 生成备份文件名
func (r *LogRotator) backupName() string {
    dir := filepath.Dir(r.LogPath)
    filename := filepath.Base(r.LogPath)
    timestamp := time.Now().Format("20060102-150405")
    return filepath.Join(dir, fmt.Sprintf("%s.%s", filename, timestamp))
}

// 压缩日志文件
func (r *LogRotator) compressLogFile(src string) error {
    dest := src + ".gz"
    
    // 打开源文件
    srcFile, err := os.Open(src)
    if err != nil {
        return fmt.Errorf("无法打开源文件进行压缩: %w", err)
    }
    defer srcFile.Close()

    // 创建目标文件
    destFile, err := os.Create(dest)
    if err != nil {
        return fmt.Errorf("无法创建压缩文件: %w", err)
    }
    defer destFile.Close()

    // 创建gzip写入器
    gzipWriter := gzip.NewWriter(destFile)
    defer gzipWriter.Close()

    // 复制数据
    if _, err = io.Copy(gzipWriter, srcFile); err != nil {
        return fmt.Errorf("压缩文件失败: %w", err)
    }

    // 关闭gzip写入器以确保所有数据被写入
    if err = gzipWriter.Close(); err != nil {
        return fmt.Errorf("关闭gzip写入器失败: %w", err)
    }

    // 删除原始文件
    if err = os.Remove(src); err != nil {
        return fmt.Errorf("删除原始文件失败: %w", err)
    }

    return nil
}

// 清理旧日志
func (r *LogRotator) cleanup() error {
    if r.MaxBackups <= 0 {
        return nil
    }

    // 获取备份文件列表
    pattern := r.LogPath + ".*"
    matches, err := filepath.Glob(pattern)
    if err != nil {
        return fmt.Errorf("查找备份文件失败: %w", err)
    }

    // 按修改时间排序
    sort.Slice(matches, func(i, j int) bool {
        iInfo, _ := os.Stat(matches[i])
        jInfo, _ := os.Stat(matches[j])
        return iInfo.ModTime().Before(jInfo.ModTime())
    })

    // 删除超过数量的旧文件
    for i := 0; i < len(matches)-r.MaxBackups; i++ {
        if err := os.Remove(matches[i]); err != nil {
            fmt.Printf("删除旧日志文件失败: %v\n", err)
        }
    }

    return nil
}

// 自动轮转检查
func (r *LogRotator) autoRotate() {
    ticker := time.NewTicker(r.interval)
    defer ticker.Stop()

    for range ticker.C {
        r.mu.Lock()
        if r.shouldRotate() {
            if err := r.rotate(); err != nil {
                fmt.Printf("自动轮转日志失败: %v\n", err)
            }
        }
        r.mu.Unlock()
    }
}

func main() {
    logPath := flag.String("log", "app.log", "日志文件路径")
    maxSize := flag.Int64("size", 10*1024*1024, "日志文件最大大小(字节)")
    maxAge := flag.Duration("age", 24*time.Hour, "日志文件最长保留时间")
    maxBackups := flag.Int("backups", 5, "保留的备份数量")
    compress := flag.Bool("compress", true, "是否压缩旧日志")
    rotateByTime := flag.Bool("time-rotate", true, "是否按时间轮转")
    flag.Parse()

    // 创建日志轮转器
    rotator, err := NewLogRotator(
        *logPath,
        *maxSize,
        *maxAge,
        *maxBackups,
        *compress,
        *rotateByTime,
    )
    if err != nil {
        fmt.Fprintf(os.Stderr, "创建日志轮转器失败: %v\n", err)
        os.Exit(1)
    }
    defer rotator.Close()

    // 模拟日志写入
    fmt.Println("开始写入日志，按Ctrl+C退出...")
    
    // 每秒写入一条日志
    i := 0
    for {
        i++
        logLine := fmt.Sprintf("[%s] 日志条目 #%d: 这是一条测试日志\n", 
            time.Now().Format(time.RFC3339),
            i)
        
        if _, err := rotator.Write([]byte(logLine)); err != nil {
            fmt.Printf("写入日志失败: %v\n", err)
        }
        
        time.Sleep(time.Second)
    }
} 
```

### 3. 创建文件监控和同步工具

**要求**:
- 监控指定目录的文件变化
- 实时同步变化到备份目录
- 支持忽略特定文件或目录
- 提供变更记录和报告

**核心实现**:

```go
package main

import (
    "flag"
    "fmt"
    "io"
    "log"
    "os"
    "path/filepath"
    "strings"
    "time"

    "github.com/fsnotify/fsnotify"
)

// 同步配置
type SyncConfig struct {
    SourceDir      string   // 源目录
    DestDir        string   // 目标目录
    IgnorePatterns []string // 忽略的文件模式
    LogFile        string   // 日志文件
    Interval       int      // 初始同步间隔(秒)
}

// 同步管理器
type SyncManager struct {
    config  SyncConfig
    watcher *fsnotify.Watcher
    logger  *log.Logger
}

// 创建新的同步管理器
func NewSyncManager(config SyncConfig) (*SyncManager, error) {
    // 创建文件系统监控器
    watcher, err := fsnotify.NewWatcher()
    if err != nil {
        return nil, fmt.Errorf("创建文件监控器失败: %w", err)
    }

    // 创建日志记录器
    var logger *log.Logger
    if config.LogFile != "" {
        logFile, err := os.OpenFile(config.LogFile, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil {
            return nil, fmt.Errorf("打开日志文件失败: %w", err)
        }
        logger = log.New(logFile, "", log.LstdFlags)
    } else {
        logger = log.New(os.Stdout, "", log.LstdFlags)
    }

    return &SyncManager{
        config:  config,
        watcher: watcher,
        logger:  logger,
    }, nil
}

// 启动同步管理
func (sm *SyncManager) Start() error {
    // 执行初始同步
    sm.logger.Println("执行初始同步...")
    if err := sm.syncAll(); err != nil {
        return fmt.Errorf("初始同步失败: %w", err)
    }

    // 添加目录到监控
    sm.logger.Println("开始监控目录变化...")
    if err := sm.addDirsToWatch(sm.config.SourceDir); err != nil {
        return fmt.Errorf("添加监控目录失败: %w", err)
    }

    // 处理文件系统事件
    go sm.handleEvents()

    return nil
}

// 停止同步管理
func (sm *SyncManager) Stop() error {
    return sm.watcher.Close()
}

// 递归添加目录到监控
func (sm *SyncManager) addDirsToWatch(dir string) error {
    return filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }

        // 检查是否应该忽略此路径
        if sm.shouldIgnore(path) {
            if info.IsDir() {
                return filepath.SkipDir
            }
            return nil
        }

        // 只监控目录
        if info.IsDir() {
            if err := sm.watcher.Add(path); err != nil {
                sm.logger.Printf("无法监控目录 %s: %v", path, err)
                return nil // 继续处理其他目录
            }
            sm.logger.Printf("添加监控目录: %s", path)
        }

        return nil
    })
}

// 检查是否应该忽略路径
func (sm *SyncManager) shouldIgnore(path string) bool {
    relPath, err := filepath.Rel(sm.config.SourceDir, path)
    if err != nil {
        return false
    }

    // 检查是否匹配任何忽略模式
    for _, pattern := range sm.config.IgnorePatterns {
        matched, err := filepath.Match(pattern, relPath)
        if err == nil && matched {
            return true
        }
        
        // 检查目录模式
        if strings.HasPrefix(relPath, pattern) || strings.HasPrefix(pattern, relPath) {
            return true
        }
    }

    return false
}

// 处理文件系统事件
func (sm *SyncManager) handleEvents() {
    for {
        select {
        case event, ok := <-sm.watcher.Events:
            if !ok {
                return
            }
            
            // 忽略某些临时文件操作
            if sm.shouldIgnore(event.Name) {
                continue
            }

            // 处理各种事件类型
            switch {
            case event.Op&fsnotify.Create == fsnotify.Create:
                sm.logger.Printf("检测到创建: %s", event.Name)
                if err := sm.handleCreate(event.Name); err != nil {
                    sm.logger.Printf("处理创建事件失败: %v", err)
                }
                
            case event.Op&fsnotify.Write == fsnotify.Write:
                sm.logger.Printf("检测到修改: %s", event.Name)
                if err := sm.handleModify(event.Name); err != nil {
                    sm.logger.Printf("处理修改事件失败: %v", err)
                }
                
            case event.Op&fsnotify.Remove == fsnotify.Remove:
                sm.logger.Printf("检测到删除: %s", event.Name)
                if err := sm.handleDelete(event.Name); err != nil {
                    sm.logger.Printf("处理删除事件失败: %v", err)
                }
                
            case event.Op&fsnotify.Rename == fsnotify.Rename:
                sm.logger.Printf("检测到重命名: %s", event.Name)
                if err := sm.handleDelete(event.Name); err != nil {
                    sm.logger.Printf("处理重命名事件失败: %v", err)
                }
            }

        case err, ok := <-sm.watcher.Errors:
            if !ok {
                return
            }
            sm.logger.Printf("监控错误: %v", err)
        }
    }
}

// 处理创建事件
func (sm *SyncManager) handleCreate(srcPath string) error {
    // 获取相对路径
    relPath, err := filepath.Rel(sm.config.SourceDir, srcPath)
    if err != nil {
        return err
    }
    
    destPath := filepath.Join(sm.config.DestDir, relPath)
    
    // 检查是目录还是文件
    info, err := os.Stat(srcPath)
    if err != nil {
        return err
    }
    
    if info.IsDir() {
        // 创建目录
        if err := os.MkdirAll(destPath, info.Mode()); err != nil {
            return err
        }
        
        // 添加新目录到监控
        if err := sm.watcher.Add(srcPath); err != nil {
            sm.logger.Printf("无法监控新目录 %s: %v", srcPath, err)
        }
    } else {
        // 复制文件
        if err := sm.copyFile(srcPath, destPath); err != nil {
            return err
        }
    }
    
    return nil
}

// 处理修改事件
func (sm *SyncManager) handleModify(srcPath string) error {
    // 忽略目录修改事件
    info, err := os.Stat(srcPath)
    if err != nil {
        if os.IsNotExist(err) {
            return nil // 文件可能已被删除
        }
        return err
    }
    
    if info.IsDir() {
        return nil
    }
    
    // 获取相对路径
    relPath, err := filepath.Rel(sm.config.SourceDir, srcPath)
    if err != nil {
        return err
    }
    
    destPath := filepath.Join(sm.config.DestDir, relPath)
    
    // 复制文件
    return sm.copyFile(srcPath, destPath)
}

// 处理删除事件
func (sm *SyncManager) handleDelete(srcPath string) error {
    // 获取相对路径
    relPath, err := filepath.Rel(sm.config.SourceDir, srcPath)
    if err != nil {
        return err
    }
    
    destPath := filepath.Join(sm.config.DestDir, relPath)
    
    // 删除目标路径
    err = os.RemoveAll(destPath)
    if err != nil && !os.IsNotExist(err) {
        return err
    }
    
    return nil
}

// 复制文件
func (sm *SyncManager) copyFile(src, dst string) error {
    // 创建目标目录
    if err := os.MkdirAll(filepath.Dir(dst), 0755); err != nil {
        return err
    }
    
    // 打开源文件
    srcFile, err := os.Open(src)
    if err != nil {
        return err
    }
    defer srcFile.Close()
    
    // 获取源文件信息
    srcInfo, err := srcFile.Stat()
    if err != nil {
        return err
    }
    
    // 创建目标文件
    dstFile, err := os.OpenFile(dst, os.O_CREATE|os.O_WRONLY|os.O_TRUNC, srcInfo.Mode())
    if err != nil {
        return err
    }
    defer dstFile.Close()
    
    // 复制内容
    _, err = io.Copy(dstFile, srcFile)
    if err != nil {
        return err
    }
    
    // 保持修改时间一致
    return os.Chtimes(dst, time.Now(), srcInfo.ModTime())
}

// 同步所有文件
func (sm *SyncManager) syncAll() error {
    return filepath.Walk(sm.config.SourceDir, func(srcPath string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        // 检查是否应该忽略此路径
        if sm.shouldIgnore(srcPath) {
            if info.IsDir() {
                return filepath.SkipDir
            }
            return nil
        }
        
        // 获取相对路径
        relPath, err := filepath.Rel(sm.config.SourceDir, srcPath)
        if err != nil {
            return err
        }
        
        destPath := filepath.Join(sm.config.DestDir, relPath)
        
        // 处理目录
        if info.IsDir() {
            return os.MkdirAll(destPath, info.Mode())
        }
        
        // 处理文件
        return sm.copyFile(srcPath, destPath)
    })
}

// 生成同步报告
func (sm *SyncManager) generateReport() (string, error) {
    var stats struct {
        TotalFiles    int
        TotalDirs     int
        TotalSize     int64
        IgnoredFiles  int
        IgnoredDirs   int
        SyncTime      time.Time
    }
    
    stats.SyncTime = time.Now()
    
    // 收集统计信息
    err := filepath.Walk(sm.config.SourceDir, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        if sm.shouldIgnore(path) {
            if info.IsDir() {
                stats.IgnoredDirs++
                return filepath.SkipDir
            }
            stats.IgnoredFiles++
            return nil
        }
        
        if info.IsDir() {
            stats.TotalDirs++
        } else {
            stats.TotalFiles++
            stats.TotalSize += info.Size()
        }
        
        return nil
    })
    
    if err != nil {
        return "", err
    }
    
    // 生成报告
    report := fmt.Sprintf(`
同步报告 - %s
------------------------------------
源目录: %s
目标目录: %s
总文件数: %d
总目录数: %d
总大小: %.2f MB
忽略的文件: %d
忽略的目录: %d
------------------------------------
`,
        stats.SyncTime.Format("2006-01-02 15:04:05"),
        sm.config.SourceDir,
        sm.config.DestDir,
        stats.TotalFiles,
        stats.TotalDirs,
        float64(stats.TotalSize)/(1024*1024),
        stats.IgnoredFiles,
        stats.IgnoredDirs,
    )
    
    return report, nil
}

func main() {
    sourceDir := flag.String("src", "", "源目录")
    destDir := flag.String("dst", "", "目标目录")
    ignore := flag.String("ignore", ".git,*.tmp,*.swp", "忽略的文件模式(逗号分隔)")
    logFile := flag.String("log", "sync.log", "日志文件")
    interval := flag.Int("interval", 60, "初始同步间隔(秒)")
    report := flag.Bool("report", false, "仅生成报告")
    flag.Parse()
    
    if *sourceDir == "" || *destDir == "" {
        flag.Usage()
        os.Exit(1)
    }
    
    // 解析忽略模式
    ignorePatterns := strings.Split(*ignore, ",")
    
    config := SyncConfig{
        SourceDir:      *sourceDir,
        DestDir:        *destDir,
        IgnorePatterns: ignorePatterns,
        LogFile:        *logFile,
        Interval:       *interval,
    }
    
    sm, err := NewSyncManager(config)
    if err != nil {
        fmt.Fprintf(os.Stderr, "创建同步管理器失败: %v\n", err)
        os.Exit(1)
    }
    defer sm.Stop()
    
    if *report {
        // 仅生成报告
        report, err := sm.generateReport()
        if err != nil {
            fmt.Fprintf(os.Stderr, "生成报告失败: %v\n", err)
            os.Exit(1)
        }
        fmt.Println(report)
    } else {
        // 启动同步管理器
        if err := sm.Start(); err != nil {
            fmt.Fprintf(os.Stderr, "启动同步管理器失败: %v\n", err)
            os.Exit(1)
        }
        
        fmt.Println("文件同步工具已启动，按Ctrl+C退出...")
        
        // 阻止主线程退出
        select {}
    }
}
```

### 4. 实现高性能的文件搜索功能

**要求**:
- 支持按内容搜索文件
- 使用多线程加速大目录搜索
- 支持正则表达式匹配
- 优化内存使用，支持搜索超大文件

**核心实现**:

```go
package main

import (
    "bufio"
    "flag"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "regexp"
    "runtime"
    "strings"
    "sync"
    "time"
)

// 搜索选项
type SearchOptions struct {
    Pattern        string   // 搜索模式
    Directories    []string // 要搜索的目录
    FilePatterns   []string // 文件名模式
    MaxDepth       int      // 最大搜索深度
    CaseSensitive  bool     // 区分大小写
    Recursive      bool     // 递归搜索
    UseRegex       bool     // 使用正则表达式
    MaxFileSize    int64    // 最大文件大小(MB)
    Workers        int      // 工作线程数
    ShowLineNumber bool     // 显示行号
    MaxResults     int      // 最大结果数
}

// 搜索结果
type SearchResult struct {
    FilePath    string // 文件路径
    LineNumber  int    // 行号
    Line        string // 匹配的行
    MatchedText string // 匹配的文本
}

// 搜索引擎
type SearchEngine struct {
    options SearchOptions
    
    resultChan   chan SearchResult
    fileChan     chan string
    resultsMutex sync.Mutex
    results      []SearchResult
    fileCount    int
    matchCount   int
    
    wg sync.WaitGroup
}

// 创建新的搜索引擎
func NewSearchEngine(options SearchOptions) *SearchEngine {
    if options.Workers <= 0 {
        options.Workers = runtime.NumCPU()
    }
    
    return &SearchEngine{
        options:    options,
        resultChan: make(chan SearchResult),
        fileChan:   make(chan string, options.Workers*2),
        results:    make([]SearchResult, 0),
    }
}

// 执行搜索
func (se *SearchEngine) Search() ([]SearchResult, error) {
    startTime := time.Now()
    
    // 启动工作线程
    for i := 0; i < se.options.Workers; i++ {
        se.wg.Add(1)
        go se.worker()
    }
    
    // 启动结果收集线程
    resultDone := make(chan struct{})
    go func() {
        for result := range se.resultChan {
            se.resultsMutex.Lock()
            se.results = append(se.results, result)
            se.matchCount++
            se.resultsMutex.Unlock()
            
            // 检查是否达到最大结果数
            if se.options.MaxResults > 0 && se.matchCount >= se.options.MaxResults {
                break
            }
        }
        close(resultDone)
    }()
    
    // 搜索文件
    for _, dir := range se.options.Directories {
        err := se.findFiles(dir, 0)
        if err != nil {
            return nil, err
        }
    }
    
    // 关闭文件通道，表示没有更多文件
    close(se.fileChan)
    
    // 等待所有工作线程完成
    se.wg.Wait()
    
    // 关闭结果通道，表示没有更多结果
    close(se.resultChan)
    
    // 等待结果收集完成
    <-resultDone
    
    duration := time.Since(startTime)
    fmt.Printf("搜索完成: 耗时 %v, 搜索了 %d 个文件, 找到 %d 个匹配\n", 
        duration, se.fileCount, se.matchCount)
    
    return se.results, nil
}

// 工作线程
func (se *SearchEngine) worker() {
    defer se.wg.Done()
    
    var regex *regexp.Regexp
    var err error
    
    // 如果使用正则表达式，预编译
    if se.options.UseRegex {
        if se.options.CaseSensitive {
            regex, err = regexp.Compile(se.options.Pattern)
        } else {
            regex, err = regexp.Compile("(?i)" + se.options.Pattern)
        }
        
        if err != nil {
            fmt.Fprintf(os.Stderr, "正则表达式编译错误: %v\n", err)
            return
        }
    }
    
    for filePath := range se.fileChan {
        // 检查最大结果数
        if se.options.MaxResults > 0 && se.matchCount >= se.options.MaxResults {
            return
        }
        
        err := se.searchFile(filePath, regex)
        if err != nil {
            fmt.Fprintf(os.Stderr, "搜索文件 %s 错误: %v\n", filePath, err)
        }
    }
}

// 查找文件
func (se *SearchEngine) findFiles(dir string, depth int) error {
    // 检查最大深度
    if se.options.MaxDepth > 0 && depth > se.options.MaxDepth {
        return nil
    }
    
    // 检查最大结果数
    if se.options.MaxResults > 0 && se.matchCount >= se.options.MaxResults {
        return nil
    }
    
    // 读取目录
    entries, err := os.ReadDir(dir)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        path := filepath.Join(dir, entry.Name())
        
        // 处理目录
        if entry.IsDir() {
            if se.options.Recursive {
                if err := se.findFiles(path, depth+1); err != nil {
                    fmt.Fprintf(os.Stderr, "遍历目录 %s 错误: %v\n", path, err)
                }
            }
            continue
        }
        
        // 检查文件名是否匹配
        if !se.matchFilePattern(entry.Name()) {
            continue
        }
        
        // 检查文件大小
        if se.options.MaxFileSize > 0 {
            info, err := entry.Info()
            if err != nil {
                continue
            }
            
            if info.Size() > se.options.MaxFileSize*1024*1024 {
                fmt.Printf("跳过大文件: %s (%.2f MB)\n", 
                    path, float64(info.Size())/(1024*1024))
                continue
            }
        }
        
        // 将文件发送到通道
        se.fileCount++
        se.fileChan <- path
    }
    
    return nil
}

// 检查文件名是否匹配模式
func (se *SearchEngine) matchFilePattern(filename string) bool {
    // 如果没有指定文件模式，匹配所有文件
    if len(se.options.FilePatterns) == 0 {
        return true
    }
    
    for _, pattern := range se.options.FilePatterns {
        matched, err := filepath.Match(pattern, filename)
        if err == nil && matched {
            return true
        }
    }
    
    return false
}

// 搜索单个文件
func (se *SearchEngine) searchFile(filePath string, regex *regexp.Regexp) error {
    // 打开文件
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // 检查是否是二进制文件
    if isBinaryFile(file) {
        fmt.Printf("跳过二进制文件: %s\n", filePath)
        return nil
    }
    
    // 重置文件指针
    if _, err := file.Seek(0, io.SeekStart); err != nil {
        return err
    }
    
    // 按行搜索
    scanner := bufio.NewScanner(file)
    lineNum := 0
    
    for scanner.Scan() {
        lineNum++
        line := scanner.Text()
        
        var matched bool
        var matchedText string
        
        if se.options.UseRegex {
            // 使用正则表达式匹配
            matches := regex.FindStringSubmatch(line)
            matched = len(matches) > 0
            if matched {
                matchedText = matches[0]
            }
        } else {
            // 使用简单字符串匹配
            if se.options.CaseSensitive {
                matched = strings.Contains(line, se.options.Pattern)
                matchedText = se.options.Pattern
            } else {
                matched = strings.Contains(strings.ToLower(line), strings.ToLower(se.options.Pattern))
                matchedText = se.options.Pattern
            }
        }
        
        if matched {
            result := SearchResult{
                FilePath:    filePath,
                LineNumber:  lineNum,
                Line:        line,
                MatchedText: matchedText,
            }
            
            se.resultChan <- result
            
            // 检查是否达到最大结果数
            if se.options.MaxResults > 0 && se.matchCount >= se.options.MaxResults {
                return nil
            }
        }
    }
    
    return scanner.Err()
}

// 检查是否是二进制文件
func isBinaryFile(file *os.File) bool {
    // 读取前4KB检查是否包含空字节
    buf := make([]byte, 4096)
    n, err := file.Read(buf)
    if err != nil && err != io.EOF {
        return true
    }
    
    // 检查是否包含NULL字节
    for i := 0; i < n; i++ {
        if buf[i] == 0 {
            return true
        }
    }
    
    return false
}

// 打印搜索结果
func printResults(results []SearchResult, showLineNumber bool) {
    if len(results) == 0 {
        fmt.Println("没有找到匹配项")
        return
    }
    
    for _, result := range results {
        if showLineNumber {
            fmt.Printf("%s:%d: %s\n", result.FilePath, result.LineNumber, result.Line)
        } else {
            fmt.Printf("%s: %s\n", result.FilePath, result.Line)
        }
    }
}

func main() {
    pattern := flag.String("pattern", "", "搜索模式")
    filePattern := flag.String("file", "*", "文件名模式(逗号分隔)")
    caseSensitive := flag.Bool("case", false, "区分大小写")
    recursive := flag.Bool("r", true, "递归搜索")
    useRegex := flag.Bool("regex", false, "使用正则表达式")
    maxFileSize := flag.Int64("maxsize", 10, "最大文件大小(MB)")
    workers := flag.Int("workers", runtime.NumCPU(), "工作线程数")
    showLineNumber := flag.Bool("n", true, "显示行号")
    maxResults := flag.Int("max", 1000, "最大结果数")
    maxDepth := flag.Int("depth", 0, "最大搜索深度(0表示无限)")
    flag.Parse()
    
    if *pattern == "" {
        fmt.Println("请指定搜索模式")
        flag.Usage()
        os.Exit(1)
    }
    
    // 获取搜索目录
    dirs := flag.Args()
    if len(dirs) == 0 {
        // 默认使用当前目录
        dirs = []string{"."}
    }
    
    // 解析文件模式
    filePatterns := strings.Split(*filePattern, ",")
    
    options := SearchOptions{
        Pattern:        *pattern,
        Directories:    dirs,
        FilePatterns:   filePatterns,
        MaxDepth:       *maxDepth,
        CaseSensitive:  *caseSensitive,
        Recursive:      *recursive,
        UseRegex:       *useRegex,
        MaxFileSize:    *maxFileSize,
        Workers:        *workers,
        ShowLineNumber: *showLineNumber,
        MaxResults:     *maxResults,
    }
    
    engine := NewSearchEngine(options)
    results, err := engine.Search()
    if err != nil {
        fmt.Fprintf(os.Stderr, "搜索错误: %v\n", err)
        os.Exit(1)
    }
    
    printResults(results, options.ShowLineNumber)
}
```

### 5. 开发批量文件处理工具

**要求**:
- 支持多种文件格式转换(CSV, JSON, XML等)
- 实现批量文本替换功能
- 提供文件元数据批量修改
- 优化性能，支持并行处理

**核心实现**:

```go
package main

import (
    "bufio"
    "bytes"
    "encoding/csv"
    "encoding/json"
    "encoding/xml"
    "flag"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "regexp"
    "runtime"
    "strings"
    "sync"
    "time"
)

// 处理选项
type ProcessOptions struct {
    InputDir     string            // 输入目录
    OutputDir    string            // 输出目录
    Format       string            // 转换格式
    Replace      bool              // 是否替换文本
    ReplaceFrom  string            // 替换源文本/正则
    ReplaceTo    string            // 替换目标文本
    UseRegex     bool              // 替换时使用正则表达式
    ModifyMeta   bool              // 是否修改元数据
    FilePatterns []string          // 文件模式
    Recursive    bool              // 递归处理
    Workers      int               // 工作线程数
    SkipErrors   bool              // 跳过错误
    TimeFormat   string            // 时间戳格式
    CustomAttrs  map[string]string // 自定义属性
}

// 处理结果
type ProcessResult struct {
    InputFile    string        // 输入文件
    OutputFile   string        // 输出文件
    Success      bool          // 是否成功
    ProcessTime  time.Duration // 处理时间
    Error        error         // 错误信息
    BytesWritten int64         // 写入字节数
}

// 处理统计
type ProcessStats struct {
    TotalFiles       int           // 总文件数
    SuccessFiles     int           // 成功处理的文件数
    FailedFiles      int           // 失败的文件数
    TotalTime        time.Duration // 总处理时间
    TotalBytesRead   int64         // 总读取字节数
    TotalBytesWritten int64        // 总写入字节数
    mutex            sync.Mutex    // 互斥锁
}

// 文件处理器
type FileProcessor struct {
    options    ProcessOptions
    stats      ProcessStats
    wg         sync.WaitGroup
    jobChan    chan string
    resultChan chan ProcessResult
}

// 创建新的文件处理器
func NewFileProcessor(options ProcessOptions) *FileProcessor {
    if options.Workers <= 0 {
        options.Workers = runtime.NumCPU()
    }
    
    return &FileProcessor{
        options:    options,
        jobChan:    make(chan string, options.Workers*2),
        resultChan: make(chan ProcessResult, options.Workers*2),
    }
}

// 启动处理
func (fp *FileProcessor) Process() error {
    startTime := time.Now()
    
    // 创建输出目录
    if fp.options.OutputDir != "" {
        if err := os.MkdirAll(fp.options.OutputDir, 0755); err != nil {
            return fmt.Errorf("创建输出目录失败: %w", err)
        }
    }
    
    // 启动工作线程
    for i := 0; i < fp.options.Workers; i++ {
        fp.wg.Add(1)
        go fp.worker()
    }
    
    // 启动结果收集线程
    resultsDone := make(chan struct{})
    go fp.collectResults(resultsDone)
    
    // 收集文件
    fileCount, err := fp.findAndEnqueueFiles(fp.options.InputDir)
    if err != nil {
        return fmt.Errorf("查找文件失败: %w", err)
    }
    
    fp.stats.TotalFiles = fileCount
    
    // 关闭任务通道，表示没有更多文件
    close(fp.jobChan)
    
    // 等待所有工作线程完成
    fp.wg.Wait()
    
    // 关闭结果通道
    close(fp.resultChan)
    
    // 等待结果收集完成
    <-resultsDone
    
    // 更新总处理时间
    fp.stats.TotalTime = time.Since(startTime)
    
    return nil
}

// 工作线程
func (fp *FileProcessor) worker() {
    defer fp.wg.Done()
    
    var regex *regexp.Regexp
    var err error
    
    // 如果使用正则表达式替换，预编译
    if fp.options.Replace && fp.options.UseRegex {
        regex, err = regexp.Compile(fp.options.ReplaceFrom)
        if err != nil {
            fmt.Fprintf(os.Stderr, "正则表达式编译错误: %v\n", err)
            return
        }
    }
    
    for inputFile := range fp.jobChan {
        startTime := time.Now()
        
        result := ProcessResult{
            InputFile: inputFile,
            Success:   false,
        }
        
        // 确定输出文件路径
        outputFile := inputFile
        if fp.options.OutputDir != "" {
            relPath, err := filepath.Rel(fp.options.InputDir, inputFile)
            if err != nil {
                result.Error = fmt.Errorf("计算相对路径失败: %w", err)
                fp.resultChan <- result
                continue
            }
            
            outputFile = filepath.Join(fp.options.OutputDir, relPath)
            
            // 如果需要转换格式，更改扩展名
            if fp.options.Format != "" {
                ext := filepath.Ext(outputFile)
                outputFile = outputFile[:len(outputFile)-len(ext)] + "." + fp.options.Format
            }
            
            // 创建输出目录
            outputDir := filepath.Dir(outputFile)
            if err := os.MkdirAll(outputDir, 0755); err != nil {
                result.Error = fmt.Errorf("创建输出目录失败: %w", err)
                fp.resultChan <- result
                continue
            }
        }
        
        result.OutputFile = outputFile
        
        // 处理文件
        bytesWritten, err := fp.processFile(inputFile, outputFile, regex)
        result.BytesWritten = bytesWritten
        
        if err != nil {
            result.Error = err
            result.Success = false
        } else {
            result.Success = true
        }
        
        result.ProcessTime = time.Since(startTime)
        fp.resultChan <- result
    }
}

// 处理单个文件
func (fp *FileProcessor) processFile(inputFile, outputFile string, regex *regexp.Regexp) (int64, error) {
    // 读取输入文件
    data, err := os.ReadFile(inputFile)
    if err != nil {
        return 0, fmt.Errorf("读取文件失败: %w", err)
    }
    
    var outputData []byte
    
    // 根据操作类型处理数据
    if fp.options.Format != "" {
        // 格式转换
        outputData, err = fp.convertFormat(data, inputFile, outputFile)
        if err != nil {
            return 0, fmt.Errorf("格式转换失败: %w", err)
        }
    } else if fp.options.Replace {
        // 文本替换
        if fp.options.UseRegex && regex != nil {
            outputData = regex.ReplaceAll(data, []byte(fp.options.ReplaceTo))
        } else {
            outputData = bytes.ReplaceAll(data, []byte(fp.options.ReplaceFrom), []byte(fp.options.ReplaceTo))
        }
    } else {
        // 直接复制
        outputData = data
    }
    
    // 写入输出文件
    if err := os.WriteFile(outputFile, outputData, 0644); err != nil {
        return 0, fmt.Errorf("写入文件失败: %w", err)
    }
    
    // 修改元数据（如果需要）
    if fp.options.ModifyMeta {
        if err := fp.modifyMetadata(outputFile); err != nil {
            return int64(len(outputData)), fmt.Errorf("修改元数据失败: %w", err)
        }
    }
    
    return int64(len(outputData)), nil
}

// 格式转换
func (fp *FileProcessor) convertFormat(data []byte, inputFile, outputFile string) ([]byte, error) {
    inputExt := strings.ToLower(filepath.Ext(inputFile))
    outputExt := strings.ToLower(filepath.Ext(outputFile))
    
    if inputExt == outputExt {
        return data, nil // 无需转换
    }
    
    // 从输入格式解析数据
    var parsedData interface{}
    
    switch inputExt {
    case ".json":
        if err := json.Unmarshal(data, &parsedData); err != nil {
            return nil, fmt.Errorf("解析JSON失败: %w", err)
        }
    
    case ".csv":
        reader := csv.NewReader(bytes.NewReader(data))
        records, err := reader.ReadAll()
        if err != nil {
            return nil, fmt.Errorf("解析CSV失败: %w", err)
        }
        parsedData = records
    
    case ".xml":
        var result map[string]interface{}
        if err := xml.Unmarshal(data, &result); err != nil {
            return nil, fmt.Errorf("解析XML失败: %w", err)
        }
        parsedData = result
    
    default:
        return nil, fmt.Errorf("不支持的输入格式: %s", inputExt)
    }
    
    // 转换为输出格式
    var outputData []byte
    var err error
    
    switch outputExt {
    case ".json":
        outputData, err = json.MarshalIndent(parsedData, "", "  ")
        if err != nil {
            return nil, fmt.Errorf("转换为JSON失败: %w", err)
        }
    
    case ".csv":
        records, ok := parsedData.([][]string)
        if !ok {
            // 尝试将数据转换为CSV格式
            jsonData, err := json.Marshal(parsedData)
            if err != nil {
                return nil, fmt.Errorf("转换数据格式失败: %w", err)
            }
            
            var mapData []map[string]interface{}
            if err := json.Unmarshal(jsonData, &mapData); err != nil {
                return nil, fmt.Errorf("转换数据格式失败: %w", err)
            }
            
            // 从第一个对象获取字段名
            if len(mapData) == 0 {
                return nil, fmt.Errorf("没有数据可转换为CSV")
            }
            
            var headers []string
            for key := range mapData[0] {
                headers = append(headers, key)
            }
            
            records = make([][]string, len(mapData)+1)
            records[0] = headers
            
            for i, item := range mapData {
                row := make([]string, len(headers))
                for j, header := range headers {
                    if val, ok := item[header]; ok {
                        row[j] = fmt.Sprintf("%v", val)
                    }
                }
                records[i+1] = row
            }
         }
         
         buf := &bytes.Buffer{}
         writer := csv.NewWriter(buf)
         if err := writer.WriteAll(records); err != nil {
             return nil, fmt.Errorf("写入CSV失败: %w", err)
         }
         writer.Flush()
         
         outputData = buf.Bytes()
     
     case ".xml":
         // 简单XML转换（实际应用中需要更复杂的处理）
         buf := &bytes.Buffer{}
         encoder := xml.NewEncoder(buf)
         encoder.Indent("", "  ")
         
         if err := encoder.Encode(parsedData); err != nil {
             return nil, fmt.Errorf("转换为XML失败: %w", err)
         }
         
         outputData = buf.Bytes()
     
     default:
         return nil, fmt.Errorf("不支持的输出格式: %s", outputExt)
     }
     
     return outputData, nil
 }
 
 // 修改文件元数据
 func (fp *FileProcessor) modifyMetadata(filePath string) error {
     // 修改文件时间
     if fp.options.TimeFormat != "" {
         parsedTime, err := time.Parse(fp.options.TimeFormat, time.Now().Format(fp.options.TimeFormat))
         if err != nil {
             return fmt.Errorf("解析时间格式失败: %w", err)
         }
         
         if err := os.Chtimes(filePath, parsedTime, parsedTime); err != nil {
             return fmt.Errorf("修改文件时间失败: %w", err)
         }
     }
     
     // 修改文件权限（仅示例，实际应用可能需要更复杂的处理）
     if attr, ok := fp.options.CustomAttrs["mode"]; ok {
         var mode os.FileMode
         if _, err := fmt.Sscanf(attr, "%o", &mode); err == nil {
             if err := os.Chmod(filePath, mode); err != nil {
                 return fmt.Errorf("修改文件权限失败: %w", err)
             }
         }
     }
     
     return nil
 }
 
 // 查找并添加文件到队列
 func (fp *FileProcessor) findAndEnqueueFiles(dir string) (int, error) {
     fileCount := 0
     
     walkFn := func(path string, info os.FileInfo, err error) error {
         if err != nil {
             if fp.options.SkipErrors {
                 fmt.Fprintf(os.Stderr, "警告: 访问 %s 失败: %v\n", path, err)
                 return nil
             }
             return err
         }
         
         // 跳过目录
         if info.IsDir() {
             if path != dir && !fp.options.Recursive {
                 return filepath.SkipDir
             }
             return nil
         }
         
         // 检查文件模式
         if !fp.matchFilePattern(info.Name()) {
             return nil
         }
         
         // 添加文件到队列
         fp.jobChan <- path
         fileCount++
         
         return nil
     }
     
     if err := filepath.Walk(dir, walkFn); err != nil {
         return fileCount, err
     }
     
     return fileCount, nil
 }
 
 // 检查文件名是否匹配模式
 func (fp *FileProcessor) matchFilePattern(filename string) bool {
     if len(fp.options.FilePatterns) == 0 {
         return true
     }
     
     for _, pattern := range fp.options.FilePatterns {
         matched, err := filepath.Match(pattern, filename)
         if err == nil && matched {
             return true
         }
     }
     
     return false
 }
 
 // 收集处理结果
 func (fp *FileProcessor) collectResults(done chan<- struct{}) {
     for result := range fp.resultChan {
         fp.stats.mutex.Lock()
         
         if result.Success {
             fp.stats.SuccessFiles++
             fp.stats.TotalBytesWritten += result.BytesWritten
             fmt.Printf("成功: %s -> %s (%.2f KB, %v)\n", 
                 result.InputFile, result.OutputFile, 
                 float64(result.BytesWritten)/1024, result.ProcessTime)
         } else {
             fp.stats.FailedFiles++
             fmt.Printf("失败: %s: %v\n", result.InputFile, result.Error)
         }
         
         fp.stats.mutex.Unlock()
     }
     
     close(done)
 }
 
 // 打印处理统计
 func (fp *FileProcessor) PrintStats() {
     fmt.Printf("\n处理统计:\n")
     fmt.Printf("总文件数: %d\n", fp.stats.TotalFiles)
     fmt.Printf("成功处理: %d\n", fp.stats.SuccessFiles)
     fmt.Printf("处理失败: %d\n", fp.stats.FailedFiles)
     fmt.Printf("总处理时间: %v\n", fp.stats.TotalTime)
     fmt.Printf("总写入数据: %.2f MB\n", float64(fp.stats.TotalBytesWritten)/(1024*1024))
     
     if fp.stats.TotalFiles > 0 {
         successRate := float64(fp.stats.SuccessFiles) / float64(fp.stats.TotalFiles) * 100
         fmt.Printf("成功率: %.1f%%\n", successRate)
     }
     
     if fp.stats.TotalTime > 0 {
         filesPerSecond := float64(fp.stats.SuccessFiles) / fp.stats.TotalTime.Seconds()
         fmt.Printf("处理速度: %.2f 文件/秒\n", filesPerSecond)
     }
 }
 
 func main() {
     inputDir := flag.String("input", ".", "输入目录")
     outputDir := flag.String("output", "", "输出目录")
     format := flag.String("format", "", "转换格式 (json, csv, xml)")
     replace := flag.Bool("replace", false, "启用文本替换")
     replaceFrom := flag.String("from", "", "替换源文本/正则")
     replaceTo := flag.String("to", "", "替换目标文本")
     useRegex := flag.Bool("regex", false, "替换时使用正则表达式")
     modifyMeta := flag.Bool("meta", false, "修改文件元数据")
     filePattern := flag.String("pattern", "*", "文件名模式(逗号分隔)")
     recursive := flag.Bool("recursive", true, "递归处理")
     workers := flag.Int("workers", runtime.NumCPU(), "工作线程数")
     skipErrors := flag.Bool("skip-errors", true, "跳过错误")
     timeFormat := flag.String("time-format", "2006-01-02 15:04:05", "时间戳格式")
     customAttrs := flag.String("attrs", "", "自定义属性 (key=value,key=value)")
     flag.Parse()
     
     // 检查参数
     if *replace && (*replaceFrom == "" || *replaceTo == "") {
         fmt.Println("错误: 替换模式需要同时指定 -from 和 -to 参数")
         flag.Usage()
         os.Exit(1)
     }
     
     // 解析文件模式
     filePatterns := strings.Split(*filePattern, ",")
     
     // 解析自定义属性
     attrs := make(map[string]string)
     if *customAttrs != "" {
         pairs := strings.Split(*customAttrs, ",")
         for _, pair := range pairs {
             kv := strings.SplitN(pair, "=", 2)
             if len(kv) == 2 {
                 attrs[kv[0]] = kv[1]
             }
         }
     }
     
     options := ProcessOptions{
         InputDir:     *inputDir,
         OutputDir:    *outputDir,
         Format:       *format,
         Replace:      *replace,
         ReplaceFrom:  *replaceFrom,
         ReplaceTo:    *replaceTo,
         UseRegex:     *useRegex,
         ModifyMeta:   *modifyMeta,
         FilePatterns: filePatterns,
         Recursive:    *recursive,
         Workers:      *workers,
         SkipErrors:   *skipErrors,
         TimeFormat:   *timeFormat,
         CustomAttrs:  attrs,
     }
     
     processor := NewFileProcessor(options)
     fmt.Println("开始批量处理文件...")
     
     if err := processor.Process(); err != nil {
         fmt.Fprintf(os.Stderr, "处理失败: %v\n", err)
         os.Exit(1)
     }
     
     processor.PrintStats()
 }